# üìú Objetivo

Este documento complementa o `README.md` e registra **decis√µes t√©cnicas**, **mudan√ßas importantes**, **erros e corre√ß√µes**, seguindo o **PROTOCOLO V5.4**.  

Cada entrada tem data, descri√ß√£o clara e v√≠nculo com o fluxo de versionamento.

Desenvolvido e atualizado pelo Obsidian

---

## üìå Estrutura

- Cada bloco √© datado no padr√£o `YYYY-MM-DD`.
- Use marcadores curtos e claros.
- Cada decis√£o deve ter justificativa quando aplic√°vel.

---

## üìÖ Hist√≥rico

---

### ‚úÖ 2025-07-12

- Estrutura inicial do **DevContainer** criada com **Python 3.10**.
- **Cliente SSH (`openssh-client`) adicionado** ao `Dockerfile` para suportar `git push` via SSH.
- **Fluxo de push ajustado:** troca para HTTPS validada quando chave SSH n√£o estava presente.
- **`Makefile` removido:** definido que n√£o ser√° usado neste prot√≥tipo, pois n√£o faz parte do fluxo real.
- **`requirements.txt` revisado:** alinhado ao `Dockerfile`, cobrindo `mlflow`, `dvc[all]`, `fastapi`, `streamlit` e libs auxiliares.
- **Vault duplicado detectado:** `cofre_remoto_mba_mlops/` removido para evitar ru√≠do.
- **Pasta `.obsidian/workspace.json` ignorada no Git:** n√£o rastrear estado de janelas.
  
  ### ‚úÖ 2025-07-12 ‚Äî Continua√ß√£o

- **Rede Docker `mlops_network` criada:** DevContainer e MinIO orquestrados no mesmo `docker-compose.yml`.
- **MinIO container rodando:** configurado com `wrm` / `senha_segura`, bucket `mba-mlops-bucket` criado via `mc` (CLI).
- **`dvc init` conclu√≠do:** reposit√≥rio DVC inicializado e versionado no Git.
- **`dvc remote add` configurado:** backend MinIO definido como remoto padr√£o com `endpointurl: http://minio:9000`.
- **`dvc push` testado:** arquivo dummy versionado com sucesso, rastre√°vel no bucket.
- **Infra validada end-to-end:** Compose, rede, bucket, push coerente.

---
### ‚úÖ 2025-07-12 ‚Äî Infra Compose Unificado: Windows + Linux

- Consolidado o diret√≥rio de trabalho em `C:\Users\wilso\MBA_MLOPS` montado em `/mnt/c/Users/wilso/MBA_MLOPS` no WSL.
- Definido bind mount persistente do volume PostgreSQL em `/home/wrm/pgdata` (FS Linux), evitando conflito NTFS.
- Validado subida de `postgres_mlflow` com `docker-compose up -d` rodando no FS montado.
- Conex√£o testada com `psql` ‚Üí `mlflow_db` dispon√≠vel.




üìå **√öltima atualiza√ß√£o:** 2025-07-12



---

### ‚úÖ 2025-07-12 ‚Äî Continua√ß√£o: Decis√£o de Migra√ß√£o Windows ‚ûù Linux

- Ap√≥s validar a infraestrutura com **DevContainer**, **MinIO**, **DVC** e **docker-compose** rodando no ambiente Windows/WSL, detectou-se **confus√£o estrutural recorrente** entre:
  - Bind mounts entre **NTFS (Windows)** e **FS Linux (WSL)**.
  - Caminhos misturados (`/mnt/c/...` vs `/home/wrm/...`), gerando **inconsist√™ncias em push/pull** de artefatos pesados.
  - Problemas para renderizar imagens no `README.md` devido a diverg√™ncias de versionamento local vs. GitHub.

- Identificado tamb√©m ru√≠do na montagem do **Vault Obsidian**:
  - Configura√ß√£o do Vault duplicada entre host Windows e WSL.
  - Estado do `.obsidian/` nem sempre coerente com o reposit√≥rio Git.

- **Ambiente Windows/WSL** exigia Docker Desktop para orquestra√ß√£o, mas:
  - O `docker compose` V2 rodava em NTFS, sofrendo permiss√µes inconsistentes em volumes persistentes.
  - A rede `mlops_network` ficava sujeita a travamentos se paths n√£o estivessem 100% alinhados.

- Para eliminar todos os riscos de permiss√µes cruzadas, foi decidido:
  1Ô∏è‚É£ **Zerar o reposit√≥rio WSL**, re-clonar o master `MBA_MLOPS` no **notebook Linux nativo**.
  2Ô∏è‚É£ Configurar o **Docker Engine CE** diretamente via `apt` (sem Snap), garantindo compatibilidade total com Compose V2.
  3Ô∏è‚É£ Recriar o ambiente de chaves SSH, vinculando `id_ed25519` ao GitHub com `noreply` para push rastre√°vel.
  4Ô∏è‚É£ Tornar o ambiente **rootless** para `docker`, adicionando `wrm` ao grupo `docker`.

- A partir desta etapa:
  - **Infraestrutura**: `docker.sh` criado na pasta pessoal (`/home/wrm/`) para orquestrar Compose por CLI puro, sem Docker Desktop.
  - **Vault Obsidian**: Consolidado no mesmo clone, garantido em `/home/wrm/MBA_MLOPS`.
  - **DevContainer**: Mantido na mesma rede `mlops_network`, agora 100% Linux-native, sem bind mount de NTFS.
  - **Navegador recomendado**: Brave ou Chromium, para evitar lentid√£o no render do ChatGPT.

‚úÖ Essa decis√£o **encerra o uso h√≠brido Windows/WSL** e garante rastreabilidade total:
  - Reposit√≥rio Git unificado.
  - Backend MinIO coerente.
  - Rede Docker e containers rodando sem bloqueio de permiss√£o.

---

üìå **√öltima atualiza√ß√£o:** 2025-07-12

---
---

### ‚úÖ 2025-07-13

- **DevContainer orquestrado como servi√ßo Compose**, anexado √† `mlops_network`, validado com `docker inspect` e `VS Code Remote Containers`.  
- **Push do DVC validado dentro do DevContainer**, usando `endpointurl: minio:9000`, sem conflito `localhost`/`minio`.  
- **Imagem `mlflow` customizada criada** (`Dockerfile.mlflow`), com `psycopg2-binary` instalado para backend PostgreSQL (`postgres_mlflow`).  
- **Problema de sintaxe do `command` no Compose V2 identificado:** strings com `\` falharam, causando loop `Restarting (1)`. Corrigido com `command:` no formato **lista YAML**, garantindo compatibilidade Compose V2 (`docker compose`).  
- **Registro de falhas PROTOCOLO:**  
  - `#2025-07-13-008`: Instru√ß√£o solta para edi√ß√£o manual de Compose ‚Äî viola√ß√£o do passo-a-passo √∫nico.  
  - `#2025-07-13-009`: Reincid√™ncia da heur√≠stica de ‚Äúatalho de edi√ß√£o trivial‚Äù ‚Äî bloqueio de heur√≠stica aplicado.  
- **Checklist final:** todos os containers (`postgres_mlflow`, `minio`, `mlflow`, `devcontainer_mba_mlops`) na rede √∫nica, com bind mounts coerentes, fluxo `Git ‚ûú DVC ‚ûú MinIO ‚ûú MLflow` validado end-to-end.

---
### ‚úÖ 2025-07-14 ‚Äî Ingest√£o Final e Versionamento dos Dados Reais

- **Download real executado via `kagglehub`**, dataset `credit-score-classification` baixado dentro do DevContainer, seguindo rede Compose √∫nica.
- **Diret√≥rio `data/raw/` estruturado** na raiz `/workspace`, corrigindo conflitos com `notebooks/data`.
- **Movimenta√ß√£o do dataset validada** usando `path` real sem heur√≠sticas, garantindo que `train.csv` (~30‚ÄØMiB) e `test.csv` (~15‚ÄØMiB) est√£o presentes.
- **Pipeline de versionamento revisado:** 
  - `git rm --cached` aplicado para garantir que `data/raw/` n√£o estivesse rastreado diretamente pelo Git.
  - `dvc add` executado corretamente a partir do n√≠vel `/workspace/notebooks` com path relativo `../data/raw`.
  - Cache `.dvc/cache/files/md5/` gerado com 4 blobs: 2 para os CSVs reais, 1 `.dir` e 1 bloco de controle.
- **`dvc push` realizado no terminal do container**, empurrando chunks para `mba-mlops-bucket/files/md5` no MinIO.
- **Verifica√ß√£o do backend MinIO feita via `mc`:**
  - `mc alias set` configurado dentro do container.
  - Blobs listados via `mc ls --recursive` confirmaram presen√ßa real dos hashes MD5 no bucket remoto.
- **Corre√ß√£o de heur√≠sticas:**  
  - Registro da falha de working dir causado por Kernel em `/workspace/notebooks` versus terminal em `/workspace`.
  - Registro da anula√ß√£o de qualquer infer√™ncia autom√°tica de path at√© o fim do projeto.
- **Pronto para EDA:** dados reais versionados, cache local e remoto coerentes, rastreio Git pendente de commit final.

### ‚úÖ 2025-07-14 ‚Äî EDA, Pr√©-processamento e Consolida√ß√£o dos Datasets Finalizados

- **Notebook de EDA revisitado:** executado dentro do DevContainer com Kernel validado em `/workspace` para coer√™ncia de paths.
- **Pipeline de pr√©-processamento conclu√≠do:** 
  - Convers√£o de tipos num√©ricos (`Age`, `Outstanding_Debt`, etc.) com coer√ß√£o `pd.to_numeric(errors='coerce')`.
  - Imputa√ß√£o de valores ausentes em colunas num√©ricas com mediana calculada no treino.
  - Substitui√ß√£o de placeholders (`_______`, `!@9#%8`, etc.) por `Unknown` em colunas categ√≥ricas.
  - Exclus√£o de colunas puramente identificadoras (`ID`, `Customer_ID`, `Name`, `SSN`).
  - Codifica√ß√£o de vari√°veis categ√≥ricas (`Month`, `Occupation`, `Credit_Mix`, `Payment_Behaviour`) com `pd.get_dummies()`, garantindo consist√™ncia.
- **`train_clean.csv` salvo em `data/processed/`** na raiz do reposit√≥rio `/workspace`, versionado com `DVC` e push realizado com sucesso para o backend MinIO.
- **Consolida√ß√£o do conjunto de teste:** 
  - Aplica√ß√£o do **mesmo pipeline** do treino (`train_clean.csv`) ao `test.csv`, garantindo coer√™ncia de features.
  - `test_clean.csv` salvo em `data/processed/` com **path coerente**, corrigindo tentativas anteriores que geraram diret√≥rios `data/` abaixo de `notebooks/`.
  - Vers√£o final do `test_clean.csv` registrada com `DVC`, push para MinIO validado e commit no Git coerente.
- **Decis√£o estrat√©gica:** camada `curated/` mantida como **fase posterior**, pois toda codifica√ß√£o e limpeza final permanecem dentro de `processed/` por ora, alinhado ao escopo do exerc√≠cio.
- **Registro de falha evitada:** identificado que rodar `dvc add` com `CWD` incorreto (`/workspace/notebooks`) causava erros de `working_dir`. Adotada confer√™ncia obrigat√≥ria de `CWD` antes de versionamento.
- **Pronto para fase de modelagem com MLflow:** `train_clean.csv` e `test_clean.csv` audit√°veis, versionados, push confirmados no bucket `mba-mlops-bucket`, preparados para rastreamento de experimentos.


### ‚úÖ 2025-07-14 ‚Äî Curated Layer Finalizada, Diagn√≥stico de Cardinalidade e Experimento Baseline no MLflow

- **Camada `curated/` criada:** consolidou `train_curated.csv` (~3,6‚ÄØGiB) e `test_curated.csv` (~1,8‚ÄØGiB), 100% numerificados e prontos para aprendizado supervisionado.
- **Diagn√≥stico de alta cardinalidade:** executado com `tqdm` para mapeamento de colunas n√£o num√©ricas ‚Äî identificados casos cr√≠ticos (`ID`, `Customer_ID`, `Type_of_Loan`).
- **Feature engineering aplicado:** `binning` de `Num_of_Loan` e mapeamento de `Month` para valores num√©ricos, revisado dentro de notebook.
- **Processo de versionamento revisado:** push incremental `dvc push` executado no terminal externo, remote duplicado removido para manter `storage` como default √∫nico.
- **Credenciais MinIO (`wrm` / `senha_segura`) exportadas dentro do container e kernel Python ‚Äî evitada falha `NoCredentialsError`.
- **`MLFLOW_S3_ENDPOINT_URL` configurado explicitamente:** apontando para `http://minio:9000` para garantir que `boto3` n√£o busque AWS real.
- **Experimento baseline rodado:** √Årvore de Decis√£o (`max_depth=5`), tracking `mlflow` validado com `tqdm` no loop de fitting.
- **Tracking URI interno mantido como `http://mlflow:5000`**, com links finais padronizados para `http://127.0.0.1:5000` para entrega acad√™mica.
- **Output final rastre√°vel:** Accuracy e F1 Score registrados, artefato salvo no backend MinIO/S3.
- **Pronto para expandir:** pr√≥ximo passo √© escalar para `GridSearchCV` e m√∫ltiplos runs rastreados com `mlflow`.

üìå **Decis√£o fixada:** todos os blocos t√©cnicos devem manter barra de progresso `tqdm` para fitting e splits mais demorados, com credenciais e endpoints explicitamente declarados dentro do notebook.


### ‚úÖ 2025-07-14 ‚Äî Kernel interrompido por alta cardinalidade e decis√£o de reabrir Feature Engineering

- **Situa√ß√£o:** Durante o pipeline `Curated`, o kernel Jupyter foi interrompido repetidas vezes por estouro de mem√≥ria (OOM Killer). Diagn√≥stico preliminar indicou que o dataset final atingiu ~6.300 colunas, geradas por `get_dummies()` indiscriminado, inviabilizando fitting local mesmo em ambiente i9 com 32 GB RAM.
- **Decis√£o:** Foi suspenso o push final desta vers√£o. Optou-se por **reabrir o notebook `feature_engineering_curadoria.ipynb`** para executar uma nova abordagem de Feature Engineering focada em **reduzir cardinalidade**, com binning, agrupamento de categorias raras e encoding controlado.
- **Pr√≥ximo passo registrado:** A nova camada `Curated` s√≥ ser√° consolidada e versionada no DVC ap√≥s passar por valida√ß√£o de footprint de mem√≥ria, garantindo fitting vi√°vel em ambiente local, em ader√™ncia ao **PROTOCOLO V5.4**.

### ‚úÖ 2025-07-15 ‚Äî Consolida√ß√£o Final do STAGED e Versionamento Rastre√°vel

- **Pipeline `STAGED V1 FINAL` conclu√≠do:** unificou coer√ß√£o num√©rica por `Occupation`, vari√°veis textuais limpas (`Occupation`, `Type_of_Loan_Category`), binning interpret√°vel (`Amount_invested_monthly`, `Monthly_Balance`, `Outstanding_Debt`, `Credit_Utilization_Ratio`) e One-Hot Encoding com `CategoricalDtype` fixo.
- **Kernel interrompido anteriormente por inconsist√™ncias em `working_dir`:** detectada diverg√™ncia entre `/workspace/notebooks` e `/workspace/data/` no root Git. Ponto fixo: todos os comandos `dvc add` e `git add` passam a usar caminho absoluto `/workspace/data/` dentro do notebook.
- **Bloco t√©cnico unificado criado em Python puro (`subprocess`):** sem `!`, rodando `dvc add`, `git add`, `git commit` e `dvc push` coerente. Falha do `git add .gitignore` registrada ‚Äî corrigido com verifica√ß√£o `os.path.exists()`.
- **Verifica√ß√£o de shape final:** `TRAIN` com 46 colunas, `TEST` com 45, mantendo `Credit_Score` somente no treino (target).
- **Checklist final do `STAGED`:**
  - `train_staged_v1_final.csv` e `test_staged_v1_final.csv` versionados com DVC.
  - Push conclu√≠do para o backend MinIO (`mba-mlops-bucket`).
  - Commit Git coerente, sem rastrear dados brutos.
- **Pronto para promo√ß√£o ao `CURATED`:** consolidar num√©ricos coeridos + texto + binning/OHE como snapshot baseline rastre√°vel.

üìå **Decis√£o fixada no PROTOCOLO V5.4:**  
- Todos os blocos de versionamento devem usar verifica√ß√£o de `CWD` e `os.path.exists()` para evitar conflitos de path.
- Versionamento deve ser at√¥mico: coer√ß√£o num√©rica e categ√≥rica n√£o mais separadas em blocos m√∫ltiplos.

### ‚úÖ 2025-07-15 ‚Äî Consolida√ß√£o FINAL CURATED V1.1 + Fitting supervisionado rastreado

- **Nova camada `CURATED V1.1` criada:** binning supervisionado revisado, agrupamento de categorias raras e OHE restrito aplicado apenas em vari√°veis com sentido de neg√≥cio (`Month`, `Occupation_Group`, `Payment_Behaviour`).
- **Diagn√≥stico de footprint:** shape reduzido de ~6.300 colunas para apenas 93, validando fitting local sem OOM Killer.
- **Versionamento at√¥mico:** `train_curated_v1_1.csv` e `test_curated_v1_1.csv` adicionados via `dvc add`, `dvc push` realizado com sucesso para o bucket `mba-mlops-bucket` no MinIO.
- **Fitting supervisionado baseline rodado:** `DecisionTreeClassifier` (`max_depth=5`), com `LabelEncoder` aplicado para eliminar colunas `object` remanescentes (`_Binned`, `Credit_History_Age`).
- **Endpoint S3 dentro do container corrigido:** troca de `127.0.0.1` para `minio:9000` garantiu persist√™ncia do modelo no backend MinIO sem erro `ConnectionClosedError`.
- **Tracking MLflow validado:** servidor `mlflow` na mesma rede Compose, exposto via `127.0.0.1:5000` para acesso local, com artefato salvo no bucket remoto.
- **Resultados do baseline:** Accuracy **0.6881**, F1 Macro **0.6519** ‚Äî coerente com os par√¢metros supervisionados.
- **Decis√£o fixada:** 
  - `127.0.0.1` jamais usado como endpoint interno para persist√™ncia de artefatos.
  - Todos os blocos de fitting devem manter export expl√≠cito de `MLFLOW_S3_ENDPOINT_URL` com nome de servi√ßo Docker.
  - Prints de acesso ao `127.0.0.1:5000` ficam apenas para acesso do UI fora do container.

üìå Pronto para Grid Search supervisionado, tuning de hiperpar√¢metros ou pipeline de stacking, mantendo rastreabilidade integral conforme **PROTOCOLO V5.4**.

### ‚úÖ 2025-07-22 ‚Äî Infer√™ncia Final Random Forest Tuned com Tracking MLflow

- **Problema identificado:** tentativa de carregar modelo via `mlflow.sklearn.load_model("runs:/...")` resultou em `MlflowException: Run not found`, mesmo com artefatos salvos no bucket MinIO.
- **Diagn√≥stico resolvido:** diret√≥rio `.mlruns` estava presente e v√°lido, mas o MLflow n√£o estava apontando corretamente para ele.
- **Corre√ß√£o aplicada:** inserido `mlflow.set_tracking_uri("file:/workspace/.mlruns")` explicitamente no notebook, evitando heur√≠sticas.
- **Infer√™ncia executada com sucesso:** 
  - Recarregou o modelo da execu√ß√£o `"4e56a5afe29a4a26b962c220fef03f5d"`;
  - Reaplicou `OrdinalEncoder` usando as colunas categ√≥ricas do treino;
  - Removeu a coluna `Credit_Score` do conjunto de teste;
  - Realizou predi√ß√£o final no `test_curated_v1_1.csv`;
  - Salvou o resultado em `/workspace/data/predictions/random_forest_final_test_predictions.csv`;
  - As predi√ß√µes apresentaram coer√™ncia com distribui√ß√£o prevista.

---

### ‚úÖ 2025-07-22 ‚Äî Prepara√ß√£o para Versionamento Final das Predi√ß√µes com DVC

- **Bloco de `dvc add` executado**, mas resultou em erro de `dubious ownership` no Git (`exit status 128`) ao tentar adicionar o `.dvc`.
- **Motivo do erro:** Git recusou-se a operar dentro do diret√≥rio `/workspace` por n√£o consider√°-lo seguro, conforme pol√≠tica de seguran√ßa interna.
- **Solu√ß√£o registrada e aplicada:** inserido comando:

  git config --global --add safe.directory /workspace
---

### ‚ùå 2025-07-22 ‚Äî Falha Cr√≠tica de Persist√™ncia para Consumo pela API (Erro #2025-07-22-014)

- **Erro detectado:** O pipeline de modelagem supervisionada seguiu corretamente o rastreamento com MLflow, mas **n√£o salvou externamente o modelo final nem o encoder**, inviabilizando o uso da API `api.py`.
- **Causa raiz:** O modelo foi rastreado via MLflow (`run_id: 4e56a5afe29a4a26b962c220fef03f5d`), mas o `OrdinalEncoder`, essencial para transformar os dados de entrada, **foi recriado dinamicamente no notebook e n√£o serializado**.
- **Impacto:** A API n√£o consegue realizar predi√ß√µes, pois n√£o possui os arquivos `.pkl` necess√°rios. Tentativas de infer√™ncia geraram `MlflowException` ou `KeyError` ao aplicar transforma√ß√µes.
- **Gravidade:** ALTA ‚Äî falha estrutural, rompe rastreabilidade, viola o Plano de Atividades (etapa 7) e o PROTOCOLO V5.4, item 2.3 e 3.1.
- **Corre√ß√£o aplicada:** Cria√ß√£o imediata de bloco t√©cnico para:
  - Recarregar modelo com `mlflow.sklearn.load_model(...)`;
  - Recriar e persistir `OrdinalEncoder`;
  - Salvar ambos em `/workspace/models/final_model.pkl` e `/workspace/models/final_encoder.pkl`.
- **A√ß√£o preventiva:** A partir deste ponto, **toda etapa de fitting ser√° obrigatoriamente acompanhada de bloco de persist√™ncia externa** para garantir compatibilidade com API e deploy.

### ‚úÖ 2025-07-22 ‚Äî Substitui√ß√£o do Modelo Base por Random Forest Otimizado + Registro no MLflow

- **Motiva√ß√£o:** O modelo anterior (`DecisionTreeClassifier(max_depth=5)`) apresentou acur√°cia limitada (~0.689), inferior √† performance registrada em execu√ß√µes anteriores (~0.79).
- **Decis√£o t√©cnica:** Substituir completamente a etapa `RECONSTRU√á√ÉO FINAL DO MODELO COM TRATAMENTO COMPLETO CONFORME CURATED V1.1`, adotando `RandomForestClassifier` com `GridSearchCV` (5 folds) e par√¢metros realistas.
- **Tratamento replicado:** Reaplica√ß√£o total do pipeline `curated_v1_1`, incluindo substitui√ß√£o de placeholders, convers√£o de `Credit_History_Age`, coer√ß√£o de tipos e `OrdinalEncoder` supervisionado com controle para desconhecidos.
- **Resultado final:** Melhor configura√ß√£o:  
  `{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 100}`  
  Acur√°cia no conjunto de treino: **0.8803**
- **Persist√™ncia:** 
  - Modelo salvo localmente em: `/workspace/models/final_model.pkl`
  - Encoder salvo localmente em: `/workspace/models/final_encoder.pkl`
- **Registro MLflow:**
  - Tracking URI: `file:/workspace/.mlruns`
  - Experimento: `modelo_otimizado_rf`
  - Run name: `random_forest_otimizado`
  - Par√¢metros, m√©trica e artefato registrados com sucesso.

üìå Pronto para infer√™ncia via `api.py` com artefatos rastre√°veis e performance validada.


---

### ‚ùå 2025-07-23 ‚Äî Falha cr√≠tica no consumo da API e rein√≠cio do desenvolvimento

- **Problema identificado:** Durante a tentativa de consumo do modelo via interface `Streamlit`, foi gerado erro do tipo `ValueError: columns are missing`, indicando que os dados enviados n√£o eram compat√≠veis com o pipeline de predi√ß√£o salvo.
    
- **Causa raiz:** O pipeline treinado com `OrdinalEncoder` e `KBinsDiscretizer` foi constru√≠do sobre um subconjunto reduzido das colunas reais do `curated_v1_1`, mas a aplica√ß√£o `Streamlit` preparava os dados com um conjunto muito maior de colunas (inclusive as j√° transformadas, como `Occupation_Group_*`, `*_Binned_*`, etc.).
    
- **Impacto:** A tentativa de infer√™ncia gera um `diff` entre as colunas esperadas pelo pipeline salvo e as fornecidas pelo formul√°rio JSON da API, causando exce√ß√£o em tempo de execu√ß√£o.
    
- **Gravidade:** ALTA ‚Äî impossibilita o deploy da aplica√ß√£o, mesmo com modelo funcional e encoder salvo.
    
- **Tentativas de corre√ß√£o realizadas:**
    
    - Verifica√ß√£o do pipeline `pipeline_completo.pkl` com `.named_steps['preprocessor']` para mapear as colunas esperadas.
        
    - Teste local de infer√™ncia manual com os mesmos dados ‚Äî erro persistiu.
        
    - Print do erro completo via interface Streamlit confirmou **incompatibilidade estrutural entre `X` esperado e `X` enviado**.
        
- **Decis√£o final:**
    
    1. **Arquivar o pipeline atual como falho para consumo em produ√ß√£o.**
        
    2. **Reiniciar todo o desenvolvimento, do zero, agora de forma completa, integrando os seguintes pontos desde o in√≠cio:**
        
        - Pr√©-processamento √∫nico e rastre√°vel;
            
        - Encoding supervisionado com controle de cardinalidade;
            
        - Persist√™ncia acoplada ao pipeline (`joblib`) com schema fixo;
            
        - Compatibilidade garantida com API externa (`FastAPI`, `Streamlit`, etc.);
            
        - Teste de infer√™ncia ao final do fitting para validar shape e ordem das colunas.
            



---

### üîÅ 2025-07-23 ‚Äî Decis√£o de refazer o notebook `runs_desenvolvimento` com MLflow pleno

- **Problema identificado:** A tentativa de integra√ß√£o entre o pipeline treinado (`pipeline_completo.pkl`) e a interface de consumo via API (FastAPI + Streamlit) falhou por inconsist√™ncia estrutural entre os dados esperados pelo modelo e os dados enviados pela aplica√ß√£o.
    
- **Evid√™ncia:** Erro do tipo `ValueError: columns are missing` foi registrado, evidenciando descompasso entre o vetor de entrada gerado pelo frontend e o que o pipeline espera ap√≥s transforma√ß√£o (`OrdinalEncoder` + `KBinsDiscretizer`).
    
- **Causa raiz:** O pipeline foi constru√≠do e salvo separadamente, sem garantir consist√™ncia plena com o fluxo de ingest√£o e serializa√ß√£o usado no momento da predi√ß√£o. O ciclo de ML n√£o estava fechado corretamente.
    
- **Impacto:** A aplica√ß√£o completa (modelo + API + UI) tornou-se n√£o funcional, inviabilizando o deploy e os testes de infer√™ncia em produ√ß√£o.
    

#### ‚úÖ Decis√£o estrat√©gica

A partir deste ponto, todo o desenvolvimento ser√° **refeito a partir do notebook `runs_desenvolvimento.ipynb`**, com as seguintes diretrizes fixas:

1. **Utiliza√ß√£o plena do MLflow desde o in√≠cio do ciclo**, incluindo:
    
    - Registro de modelos com hiperpar√¢metros, m√©tricas e artefatos;
        
    - Salvamento versionado com `run_id` rastre√°vel;
        
    - Log estruturado de pipelines e transforma√ß√µes;
        
    - Valida√ß√£o completa do modelo com `signature` e `input_example`.
        
2. **Elimina√ß√£o de serializa√ß√µes manuais (`joblib.dump`) avulsas**, substituindo por persist√™ncia estruturada via MLflow.
    
3. **Reformula√ß√£o do ciclo de experimenta√ß√£o**, com:
    
    - Separa√ß√£o clara entre etapas de pr√©-processamento, treino, avalia√ß√£o e exporta√ß√£o;
        
    - Conformidade entre os dados de treino e os dados esperados no deploy;
        
    - Versionamento autom√°tico e rastre√°vel de cada execu√ß√£o.
        

üìå Esta redefini√ß√£o √© mandat√≥ria e segue o **PROTOCOLO V5.4**, encerrando oficialmente a fase anterior de prototipa√ß√£o e iniciando a etapa de **desenvolvimento consolidado e pronto para produ√ß√£o**.


---

### üîé 2025-07-23 ‚Äî Discuss√£o sobre persist√™ncia do pipeline e rastreabilidade com MLflow

- **Contexto atual:** Ap√≥s a etapa de treinamento e tuning com `GridSearchCV` usando `RandomForestClassifier`, obteve-se desempenho superior ao baseline (Acur√°cia **0.7770**, F1 Macro **0.7611**), registrado e rastreado via MLflow.
    
- **Discuss√£o t√©cnica em andamento:**
    
    - Debate sobre **momento correto para persist√™ncia** do pipeline final.
        
    - Avalia√ß√£o se o encoder (`OrdinalEncoder`, `KBinsDiscretizer`) est√° sendo salvo **dentro do pipeline** rastreado, ou se √© necess√°rio salvar como artefato adicional.
        
    - Verifica√ß√£o se o pipeline final (`sklearn.pipeline.Pipeline`) inclui todas as etapas de transforma√ß√£o necess√°rias para consumo direto na API.
        
    - Conclus√£o parcial: embora o modelo esteja sendo corretamente salvo com `mlflow.sklearn.log_model(...)`, √© necess√°rio garantir que:
        
        - O **schema do input (`signature`)** seja registrado corretamente;
            
        - O **`input_example`** reflita a estrutura real de predi√ß√£o (com colunas transformadas);
            
        - As etapas de transforma√ß√£o estejam acopladas ao `Pipeline` para **evitar perda de contexto na infer√™ncia**.
            
- **Risco identificado:** Se o pipeline final n√£o estiver completo (com encoder embutido), **a API falhar√° novamente** como no ciclo anterior.
    
- **A√ß√£o determinada:**
    
    1. Garantir que o pipeline final contenha o encoder treinado e seja **√∫nico artefato serializado**;
        
    2. **Evitar m√∫ltiplos `.pkl` avulsos**, preferindo a serializa√ß√£o √∫nica do `Pipeline` completo via MLflow;
        
    3. Confirmar a compatibilidade do modelo via `mlflow.pyfunc.load_model()` e teste manual de infer√™ncia antes do deploy;
        
    4. Incluir bloco de verifica√ß√£o de `.signature` e `.input_example` no experimento antes da exporta√ß√£o final.
        

### ‚úÖ 2025-07-23 ‚Äî Etapas 2, 3 e 4 reexecutadas e modelo congelado oficialmente como vers√£o `v1-final`

Ap√≥s a detec√ß√£o de inconsist√™ncias t√©cnicas nos registros anteriores (run_id `79e0f222...` e `aea76868...`), foi refeito todo o processo de modelagem, valida√ß√£o e registro para garantir integridade completa e conformidade com o PROTOCOLO V5.5.

#### Etapa 2 (Reexecutada)

- O modelo Random Forest foi treinado diretamente com os melhores hiperpar√¢metros j√° conhecidos, sem GridSearch adicional:
  - `max_depth = 20`
  - `max_features = 'sqrt'`
  - `min_samples_leaf = 3`
  - `n_estimators = 200`
- O pipeline foi constru√≠do com `OrdinalEncoder` acoplado e serializado integralmente via `mlflow.sklearn.log_model(...)`;
- Foi salvo com `input_example` coerente, for√ßado para `object`, garantindo integridade de tipos;
- O run final foi salvo sob:
  - `run_id = 7077ebfbf696487384bd5a59034170c5`
  - `experimento = modelo_rf_otimizado_final`

#### Etapa 3 (Valida√ß√£o Completa)

- O modelo foi carregado via `pyfunc.load_model()` e testado com `X_test` real;
- A infer√™ncia foi realizada com sucesso, sem erros de shape ou tipo;
- A `signature` foi recuperada e validada estruturalmente contra as colunas reais;
- O `input_example.json` original, embora corrompido para leitura via Pandas, foi substitu√≠do por uma exporta√ß√£o rastre√°vel:
  - `input_example_rf_v1.csv` salvo em `/workspace/data/examples/`
  - Estrutura audit√°vel e version√°vel, compat√≠vel com API REST, documenta√ß√£o externa e deploys automatizados.

#### Etapa 4 (Congelamento Oficial)

- O modelo foi oficialmente promovido √† vers√£o `v1-final`;
- Foi gerado e salvo o manifesto JSON contendo os metadados da vers√£o congelada:
  - Local: `/workspace/models/congelados/manifesto_modelo_rf_v1.json`
- Este modelo √© agora a base can√¥nica para as etapas seguintes: exporta√ß√£o de pipeline, deploy da API FastAPI e interface via Streamlit.

üìå A partir deste ponto, qualquer nova altera√ß√£o deve ser registrada como nova vers√£o (`v2`, `v3`, etc.), mantendo o `v1-final` imut√°vel para rastreabilidade de produ√ß√£o.

#### Etapa 5 (Exporta√ß√£o f√≠sica, testes de API e tratamento de erros cr√≠ticos)

Com o congelamento oficial do modelo `v1-final`, iniciou-se a etapa de exporta√ß√£o f√≠sica e integra√ß√£o com as aplica√ß√µes externas (API FastAPI e interface Streamlit). No entanto, esta fase revelou uma s√©rie de erros operacionais, estruturais e conceituais, que exigiram diagn√≥stico profundo, corre√ß√µes e ajustes de protocolo.

**5.1 Exporta√ß√£o f√≠sica do modelo**

- O pipeline completo foi exportado a partir do MLflow com sucesso para:
  - `/workspace/models/exportado_rf_v1_final/pipeline`
- O manifesto auxiliar foi criado no formato `.json`, contendo `run_id`, `timestamp`, caminho do modelo e instru√ß√£o `mlflow.pyfunc.load_model(...)` para uso futuro:
  - `/workspace/models/exportado_rf_v1_final/manifesto_rf_v1.json`

**5.2 Teste inicial com FastAPI**

- O script `test_api.py` foi criado para simular chamadas √† API utilizando o exemplo salvo `input_example_rf_v1.csv`.
- Ao rodar o teste, ocorreu **erro 500**, com mensagem clara de **incompatibilidade com o schema MLflow**.
- A mensagem indicava, por exemplo: `Incompatible input types for column Month_August. Can not safely convert bool to int64`.

**5.3 Diagn√≥stico e causa raiz**

- Descobriu-se que os dados utilizados como input foram criados manualmente, desrespeitando o tipo inferido durante o registro do modelo.
- Apesar de todos os dados estarem dispon√≠veis e versionados, a infer√™ncia do schema havia sido feita com tipos espec√≠ficos (`int64`, `float64`, `string`), e n√£o permitia `bool` mesmo quando semanticamente equivalentes.
- Isso gerou **erros de schema enforcement r√≠gido** do MLflow, mesmo com estrutura de colunas correta.

**5.4 Corre√ß√£o com pipeline oficial**

- A partir do pipeline oficial registrado, foi feita uma aplica√ß√£o real sobre os dados `train_curated_v1_final.csv` para gerar um `input_example` compat√≠vel:
  - O DataFrame de entrada foi transformado com o pipeline salvo;
  - As colunas foram renomeadas e os tipos ajustados conforme o schema oficial (evitando booleanos);
  - Esse input corrigido foi usado tanto no teste da API quanto na interface Streamlit.

**5.5 Problemas com caminhos e versionamento**

- Houve falhas repetidas ao localizar os arquivos versionados, como `train_curated_v1_final.csv`;
- Isso ocorreu por **uso incorreto de caminhos antigos (`/data/staged`)**, **erros de digita√ß√£o**, e **tentativa de uso de arquivos n√£o rastreados pelo DVC**;
- Como corre√ß√£o, os caminhos foram restabelecidos com base nos notebooks anteriores (ex: `adequacao_desenvolvimento.ipynb`), e a recupera√ß√£o via DVC foi explicitamente exigida antes de qualquer uso.

**5.6 Testes finais da API e da interface Streamlit**

- Ap√≥s valida√ß√µes, o modelo `v1-final` foi corretamente carregado pela API FastAPI;
- A interface Streamlit foi conectada √† API usando o novo input;
- As predi√ß√µes foram recebidas com sucesso e exibidas corretamente.

**Conclus√£o da Etapa 5:**

- Apesar de o modelo estar congelado corretamente, a integra√ß√£o revelou falhas importantes na consist√™ncia entre input de infer√™ncia e schema inferido;
- Os erros foram solucionados com reconstru√ß√£o baseada no pipeline real;
- Foram bloqueadas heur√≠sticas de infer√™ncia autom√°tica de tipos ou nomes, passando-se a exigir input gerado diretamente pelo pipeline e vers√£o oficial.

