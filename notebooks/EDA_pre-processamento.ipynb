{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1c384c",
   "metadata": {},
   "source": [
    "## Fase 5 — EDA e Pré-processamento\n",
    "\n",
    "Nesta fase iniciaremos o **Item 5 do Plano de Atividades**, responsável por abrir a etapa de **Análise Exploratória de Dados (EDA)** do conjunto real de dados versionado.  \n",
    "O objetivo é garantir que os arquivos `train.csv` e `test.csv` estejam corretamente estruturados, analisar tipos de variáveis, valores ausentes, estatísticas básicas e possíveis inconsistências.  \n",
    "Todo o trabalho será executado dentro do **DevContainer**, com **rastreabilidade total**, utilizando sempre caminhos relativos revisados fisicamente, em conformidade com o **PROTOCOLO V5.4**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97ed987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD Kernel: /workspace/notebooks\n",
      "Conteúdo de data/raw/: ['test.csv', 'train.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_310944/465301536.py:17: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato treino: (100000, 28)\n",
      "Formato teste: (50000, 27)\n",
      "\n",
      "Tipos de colunas treino:\n",
      "ID                           object\n",
      "Customer_ID                  object\n",
      "Month                        object\n",
      "Name                         object\n",
      "Age                          object\n",
      "SSN                          object\n",
      "Occupation                   object\n",
      "Annual_Income                object\n",
      "Monthly_Inhand_Salary       float64\n",
      "Num_Bank_Accounts             int64\n",
      "Num_Credit_Card               int64\n",
      "Interest_Rate                 int64\n",
      "Num_of_Loan                  object\n",
      "Type_of_Loan                 object\n",
      "Delay_from_due_date           int64\n",
      "Num_of_Delayed_Payment       object\n",
      "Changed_Credit_Limit         object\n",
      "Num_Credit_Inquiries        float64\n",
      "Credit_Mix                   object\n",
      "Outstanding_Debt             object\n",
      "Credit_Utilization_Ratio    float64\n",
      "Credit_History_Age           object\n",
      "Payment_of_Min_Amount        object\n",
      "Total_EMI_per_month         float64\n",
      "Amount_invested_monthly      object\n",
      "Payment_Behaviour            object\n",
      "Monthly_Balance              object\n",
      "Credit_Score                 object\n",
      "dtype: object\n",
      "\n",
      "Valores nulos treino:\n",
      "ID                              0\n",
      "Customer_ID                     0\n",
      "Month                           0\n",
      "Name                         9985\n",
      "Age                             0\n",
      "SSN                             0\n",
      "Occupation                      0\n",
      "Annual_Income                   0\n",
      "Monthly_Inhand_Salary       15002\n",
      "Num_Bank_Accounts               0\n",
      "Num_Credit_Card                 0\n",
      "Interest_Rate                   0\n",
      "Num_of_Loan                     0\n",
      "Type_of_Loan                11408\n",
      "Delay_from_due_date             0\n",
      "Num_of_Delayed_Payment       7002\n",
      "Changed_Credit_Limit            0\n",
      "Num_Credit_Inquiries         1965\n",
      "Credit_Mix                      0\n",
      "Outstanding_Debt                0\n",
      "Credit_Utilization_Ratio        0\n",
      "Credit_History_Age           9030\n",
      "Payment_of_Min_Amount           0\n",
      "Total_EMI_per_month             0\n",
      "Amount_invested_monthly      4479\n",
      "Payment_Behaviour               0\n",
      "Monthly_Balance              1200\n",
      "Credit_Score                    0\n",
      "dtype: int64\n",
      "\n",
      "Amostra treino:\n",
      "        ID Customer_ID     Month             Name   Age          SSN  \\\n",
      "0   0x1602   CUS_0xd40   January    Aaron Maashoh    23  821-00-0265   \n",
      "1   0x1603   CUS_0xd40  February    Aaron Maashoh    23  821-00-0265   \n",
      "2   0x1604   CUS_0xd40     March    Aaron Maashoh  -500  821-00-0265   \n",
      "3   0x1605   CUS_0xd40     April    Aaron Maashoh    23  821-00-0265   \n",
      "4   0x1606   CUS_0xd40       May    Aaron Maashoh    23  821-00-0265   \n",
      "5   0x1607   CUS_0xd40      June    Aaron Maashoh    23  821-00-0265   \n",
      "6   0x1608   CUS_0xd40      July    Aaron Maashoh    23  821-00-0265   \n",
      "7   0x1609   CUS_0xd40    August              NaN    23    #F%$D@*&8   \n",
      "8   0x160e  CUS_0x21b1   January  Rick Rothackerj   28_  004-07-5839   \n",
      "9   0x160f  CUS_0x21b1  February  Rick Rothackerj    28  004-07-5839   \n",
      "10  0x1610  CUS_0x21b1     March  Rick Rothackerj    28  004-07-5839   \n",
      "11  0x1611  CUS_0x21b1     April  Rick Rothackerj    28  004-07-5839   \n",
      "12  0x1612  CUS_0x21b1       May  Rick Rothackerj    28  004-07-5839   \n",
      "13  0x1613  CUS_0x21b1      June  Rick Rothackerj    28  004-07-5839   \n",
      "14  0x1614  CUS_0x21b1      July  Rick Rothackerj    28  004-07-5839   \n",
      "15  0x1615  CUS_0x21b1    August  Rick Rothackerj    28  004-07-5839   \n",
      "16  0x161a  CUS_0x2dbc   January           Langep    34  486-85-3974   \n",
      "17  0x161b  CUS_0x2dbc  February              NaN    34  486-85-3974   \n",
      "18  0x161c  CUS_0x2dbc     March           Langep    34  486-85-3974   \n",
      "19  0x161d  CUS_0x2dbc     April           Langep    34  486-85-3974   \n",
      "\n",
      "   Occupation Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
      "0   Scientist      19114.12            1824.843333                  3  ...   \n",
      "1   Scientist      19114.12                    NaN                  3  ...   \n",
      "2   Scientist      19114.12                    NaN                  3  ...   \n",
      "3   Scientist      19114.12                    NaN                  3  ...   \n",
      "4   Scientist      19114.12            1824.843333                  3  ...   \n",
      "5   Scientist      19114.12                    NaN                  3  ...   \n",
      "6   Scientist      19114.12            1824.843333                  3  ...   \n",
      "7   Scientist      19114.12            1824.843333                  3  ...   \n",
      "8     _______      34847.84            3037.986667                  2  ...   \n",
      "9     Teacher      34847.84            3037.986667                  2  ...   \n",
      "10    Teacher     34847.84_            3037.986667                  2  ...   \n",
      "11    Teacher      34847.84                    NaN                  2  ...   \n",
      "12    Teacher      34847.84            3037.986667                  2  ...   \n",
      "13    Teacher      34847.84            3037.986667                  2  ...   \n",
      "14    Teacher      34847.84                    NaN                  2  ...   \n",
      "15    Teacher      34847.84            3037.986667                  2  ...   \n",
      "16    _______     143162.64           12187.220000                  1  ...   \n",
      "17   Engineer     143162.64           12187.220000                  1  ...   \n",
      "18    _______     143162.64                    NaN                  1  ...   \n",
      "19   Engineer     143162.64           12187.220000                  1  ...   \n",
      "\n",
      "    Credit_Mix  Outstanding_Debt Credit_Utilization_Ratio  \\\n",
      "0            _            809.98                26.822620   \n",
      "1         Good            809.98                31.944960   \n",
      "2         Good            809.98                28.609352   \n",
      "3         Good            809.98                31.377862   \n",
      "4         Good            809.98                24.797347   \n",
      "5         Good            809.98                27.262259   \n",
      "6         Good            809.98                22.537593   \n",
      "7         Good            809.98                23.933795   \n",
      "8         Good            605.03                24.464031   \n",
      "9         Good            605.03                38.550848   \n",
      "10           _            605.03                33.224951   \n",
      "11        Good            605.03                39.182656   \n",
      "12        Good            605.03                34.977895   \n",
      "13        Good            605.03                33.381010   \n",
      "14        Good            605.03                31.131702   \n",
      "15        Good            605.03                32.933856   \n",
      "16        Good           1303.01                28.616735   \n",
      "17        Good           1303.01                41.702573   \n",
      "18        Good           1303.01                26.519815   \n",
      "19           _           1303.01                39.501648   \n",
      "\n",
      "        Credit_History_Age  Payment_of_Min_Amount Total_EMI_per_month  \\\n",
      "0    22 Years and 1 Months                     No           49.574949   \n",
      "1                      NaN                     No           49.574949   \n",
      "2    22 Years and 3 Months                     No           49.574949   \n",
      "3    22 Years and 4 Months                     No           49.574949   \n",
      "4    22 Years and 5 Months                     No           49.574949   \n",
      "5    22 Years and 6 Months                     No           49.574949   \n",
      "6    22 Years and 7 Months                     No           49.574949   \n",
      "7                      NaN                     No           49.574949   \n",
      "8    26 Years and 7 Months                     No           18.816215   \n",
      "9    26 Years and 8 Months                     No           18.816215   \n",
      "10   26 Years and 9 Months                     No           18.816215   \n",
      "11  26 Years and 10 Months                     No           18.816215   \n",
      "12  26 Years and 11 Months                     No           18.816215   \n",
      "13   27 Years and 0 Months                     No           18.816215   \n",
      "14   27 Years and 1 Months                     NM           18.816215   \n",
      "15   27 Years and 2 Months                     No           18.816215   \n",
      "16   17 Years and 9 Months                     No          246.992319   \n",
      "17  17 Years and 10 Months                     No          246.992319   \n",
      "18  17 Years and 11 Months                     No          246.992319   \n",
      "19                     NaN                     No          246.992319   \n",
      "\n",
      "   Amount_invested_monthly                 Payment_Behaviour  \\\n",
      "0        80.41529543900253   High_spent_Small_value_payments   \n",
      "1       118.28022162236736    Low_spent_Large_value_payments   \n",
      "2          81.699521264648   Low_spent_Medium_value_payments   \n",
      "3        199.4580743910713    Low_spent_Small_value_payments   \n",
      "4       41.420153086217326  High_spent_Medium_value_payments   \n",
      "5       62.430172331195294                            !@9#%8   \n",
      "6        178.3440674122349    Low_spent_Small_value_payments   \n",
      "7       24.785216509052056  High_spent_Medium_value_payments   \n",
      "8         104.291825168246    Low_spent_Small_value_payments   \n",
      "9        40.39123782853101   High_spent_Large_value_payments   \n",
      "10       58.51597569589465   High_spent_Large_value_payments   \n",
      "11       99.30622796053305   Low_spent_Medium_value_payments   \n",
      "12      130.11542024292334    Low_spent_Small_value_payments   \n",
      "13      43.477190144355745   High_spent_Large_value_payments   \n",
      "14       70.10177420755677  High_spent_Medium_value_payments   \n",
      "15      218.90434353388733    Low_spent_Small_value_payments   \n",
      "16        168.413702679309                            !@9#%8   \n",
      "17      232.86038375993544   High_spent_Small_value_payments   \n",
      "18               __10000__   High_spent_Small_value_payments   \n",
      "19       825.2162699393922   Low_spent_Medium_value_payments   \n",
      "\n",
      "       Monthly_Balance Credit_Score  \n",
      "0   312.49408867943663         Good  \n",
      "1   284.62916249607184         Good  \n",
      "2    331.2098628537912         Good  \n",
      "3   223.45130972736786         Good  \n",
      "4   341.48923103222177         Good  \n",
      "5    340.4792117872438         Good  \n",
      "6    244.5653167062043         Good  \n",
      "7   358.12416760938714     Standard  \n",
      "8   470.69062692529184     Standard  \n",
      "9    484.5912142650067         Good  \n",
      "10  466.46647639764313     Standard  \n",
      "11   465.6762241330048         Good  \n",
      "12   444.8670318506144         Good  \n",
      "13    481.505261949182         Good  \n",
      "14   464.8806778859809         Good  \n",
      "15  356.07810855965045         Good  \n",
      "16  1043.3159778669492         Good  \n",
      "17   998.8692967863226         Good  \n",
      "18    715.741367403555         Good  \n",
      "19   426.5134106068658         Good  \n",
      "\n",
      "[20 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CARREGAR E INSPECIONAR O DATASET REAL\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Confirma diretório de trabalho do Kernel\n",
    "print(\"CWD Kernel:\", os.getcwd())\n",
    "\n",
    "# Define caminho coerente para o dataset real\n",
    "# Se o notebook estiver dentro de notebooks/, usar ../data/raw/\n",
    "data_raw_dir = \"../data/raw\"\n",
    "\n",
    "# Lista arquivos para validar nomes reais\n",
    "print(\"Conteúdo de data/raw/:\", os.listdir(data_raw_dir))\n",
    "\n",
    "# Carrega arquivos reais versionados\n",
    "df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(data_raw_dir, \"test.csv\"))\n",
    "\n",
    "# Verifica estrutura inicial\n",
    "print(\"Formato treino:\", df_train.shape)\n",
    "print(\"Formato teste:\", df_test.shape)\n",
    "\n",
    "print(\"\\nTipos de colunas treino:\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "print(\"\\nValores nulos treino:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nAmostra treino:\")\n",
    "print(df_train.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50236b0c",
   "metadata": {},
   "source": [
    "## Análise da Célula de Carregamento e Inspeção Inicial\n",
    "\n",
    "A leitura dos arquivos `train.csv` e `test.csv` confirma que o dataset real está estruturado e coerente com o versionamento em `data/raw/`.  \n",
    "O `train.csv` possui **100.000 linhas × 28 colunas** e o `test.csv` **50.000 linhas × 27 colunas**. A listagem do diretório validou os nomes dos arquivos sem dependência de heurística, alinhado ao **PROTOCOLO V5.4**.\n",
    "\n",
    "### Principais observações:\n",
    "\n",
    "- **DtypeWarning:** A leitura acusou tipos mistos em algumas colunas (ex.: coluna 26), indicando registros com strings, símbolos ou formatos inconsistentes em campos que deveriam ser numéricos.\n",
    "- **Tipos de colunas:** Diversas variáveis numéricas (`Age`, `Outstanding_Debt`, `Amount_invested_monthly` etc.) foram lidas como `object`. Isso confirma a necessidade de conversão explícita para tipos numéricos (`int64` ou `float64`) usando coerção.\n",
    "- **Valores ausentes:** A contagem de `NaN` revelou lacunas relevantes em campos como `Name` (~10%), `Monthly_Inhand_Salary` (~15%), `Credit_History_Age` (~9%) e `Num_of_Delayed_Payment`. Será necessário definir políticas de imputação ou descarte.\n",
    "- **Amostra de registros:** Identificou anomalias claras, como `Age` negativo ou inválido (`-500`, `28_`), ocupações `_______` e padrões de ruído como `!@9#%8` em `Payment_Behaviour`. Estes valores precisarão ser tratados na fase de limpeza.\n",
    "\n",
    "Esta análise serve como base para planejar o pré-processamento, garantindo integridade e consistência antes de avançar para treinamento e rastreio de experimentos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa35f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Políticas de Tratamento de Dados — Definição Oficial\n",
    "\n",
    "Com base na análise exploratória inicial e nos requisitos do exercício, definimos as seguintes diretrizes de limpeza e padronização para o dataset `credit-score-classification`. Todas as etapas respeitam o **PROTOCOLO V5.4** e garantem rastreabilidade do pipeline.\n",
    "\n",
    "### 🔹 Conversão de Tipos\n",
    "- Todas as colunas identificadas como `object` mas que representam valores numéricos (ex.: `Age`, `Outstanding_Debt`, `Amount_invested_monthly`) serão convertidas para `float64` usando `pd.to_numeric(errors='coerce')`.  \n",
    "- Valores que não puderem ser convertidos se tornarão `NaN` de forma rastreável.\n",
    "\n",
    "### 🔹 Tratamento de Anomalias Numéricas\n",
    "- Idades negativas ou entradas não numéricas (ex.: `-500`, `28_`) serão convertidas em `NaN` e imputadas com a mediana da coluna `Age`.\n",
    "- Valores absurdos ou placeholders (ex.: `__10000__`) terão caracteres especiais removidos e serão convertidos para número se possível.\n",
    "\n",
    "### 🔹 Valores Ausentes\n",
    "- Variáveis numéricas contínuas com nulos (ex.: `Monthly_Inhand_Salary`, `Credit_History_Age`) serão imputadas com a mediana, pois são menos sensíveis a outliers.\n",
    "- Variáveis categóricas com nulos (ex.: `Occupation`, `Payment_Behaviour`) receberão a categoria `Unknown` para manter integridade sem supor informação.\n",
    "\n",
    "### 🔹 Outliers\n",
    "- Para colunas financeiras como `Annual_Income` e `Outstanding_Debt`, aplicaremos Winsorization limitando os extremos aos percentis 1% e 99% para reduzir impacto de valores distorcidos.\n",
    "\n",
    "### 🔹 Padronização de Strings\n",
    "- Placeholder como `_______` e ruídos do tipo `!@9#%8` serão substituídos por `Unknown`.\n",
    "- Campos com `Yes/No` serão convertidos para padrão binário se necessário na fase de modelagem.\n",
    "\n",
    "### 🔹 Split e Persistência\n",
    "- Após o tratamento, o dataset limpo será salvo em `data/processed/` versionado com DVC, pronto para rastreio no MLflow.\n",
    "- Esta etapa encerra o pré-processamento, mantendo coerência para o treino e serving via API posteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3689d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos originais:\n",
      "Age                        object\n",
      "Annual_Income              object\n",
      "Outstanding_Debt           object\n",
      "Amount_invested_monthly    object\n",
      "Monthly_Balance            object\n",
      "dtype: object\n",
      "\n",
      "Tipos após coerção:\n",
      "Age                        float64\n",
      "Annual_Income              float64\n",
      "Outstanding_Debt           float64\n",
      "Amount_invested_monthly    float64\n",
      "Monthly_Balance            float64\n",
      "dtype: object\n",
      "\n",
      "Valores NaN adicionados por coerção:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CONVERSÃO DE TIPOS NUMÉRICOS COM COERÇÃO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de colunas identificadas como numéricas, mas com tipo object\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: tipos originais\n",
    "print(\"Tipos originais:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Aplica coerção para float64\n",
    "for col in numeric_cols:\n",
    "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "\n",
    "# Depois: tipos convertidos\n",
    "print(\"\\nTipos após coerção:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Verifica quantos valores viraram NaN\n",
    "print(\"\\nValores NaN adicionados por coerção:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cf435",
   "metadata": {},
   "source": [
    "## Imputação de Valores Ausentes — Colunas Numéricas\n",
    "\n",
    "Após converter colunas numéricas para tipos coerentes, aplicamos imputação de `NaN` usando **mediana** para variáveis contínuas.  \n",
    "Esta abordagem é robusta contra distorções de valores extremos, mantém o viés controlado e respeita o histórico real do dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN antes da imputação:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n",
      "Imputado Age com mediana = 33.0\n",
      "Imputado Annual_Income com mediana = 37550.74\n",
      "Imputado Outstanding_Debt com mediana = 1166.37\n",
      "Imputado Amount_invested_monthly com mediana = 128.95453805190283\n",
      "Imputado Monthly_Balance com mediana = 336.73122455696387\n",
      "\n",
      "NaN após imputação:\n",
      "Age                        0\n",
      "Annual_Income              0\n",
      "Outstanding_Debt           0\n",
      "Amount_invested_monthly    0\n",
      "Monthly_Balance            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: IMPUTAR VALORES AUSENTES COM MEDIANA\n",
    "\n",
    "# Define novamente as colunas numéricas que já foram convertidas\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: mostra quantos NaN existem\n",
    "print(\"NaN antes da imputação:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n",
    "\n",
    "# Aplica imputação da mediana, coluna por coluna\n",
    "for col in numeric_cols:\n",
    "    median_value = df_train[col].median()\n",
    "    df_train[col] = df_train[col].fillna(median_value)\n",
    "    print(f\"Imputado {col} com mediana = {median_value}\")\n",
    "\n",
    "# Depois: verifica se ainda restaram NaN\n",
    "print(\"\\nNaN após imputação:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8867",
   "metadata": {},
   "source": [
    "## Limpeza de Placeholders e Ruídos — Colunas Categóricas\n",
    "\n",
    "Após a imputação numérica, iniciamos a padronização de colunas categóricas que apresentam valores placeholders ou símbolos de ruído.  \n",
    "Entradas como `_______`, `______`, `__`, `!@9#%8` e variações similares serão substituídas por `Unknown` para garantir consistência e coerência nos modelos.  \n",
    "Esta abordagem segue o princípio de **não supor valores** quando não há base para inferência.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2da97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coluna: Occupation\n",
      "Antes: ['Scientist' '_______' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "Depois: ['Scientist' 'Unknown' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "\n",
      "Coluna: Payment_Behaviour\n",
      "Antes: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' '!@9#%8'\n",
      " 'High_spent_Large_value_payments']\n",
      "Depois: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' 'Unknown'\n",
      " 'High_spent_Large_value_payments']\n",
      "\n",
      "Coluna: Credit_Mix\n",
      "Antes: ['_' 'Good' 'Standard' 'Bad']\n",
      "Depois: ['Unknown' 'Good' 'Standard' 'Bad']\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: LIMPEZA DE PLACEHOLDERS E RUÍDOS EM CATEGÓRICAS\n",
    "\n",
    "# Lista de colunas categóricas sensíveis a ruído (ajuste conforme necessário)\n",
    "categorical_cols = [\n",
    "    \"Occupation\",\n",
    "    \"Payment_Behaviour\",\n",
    "    \"Credit_Mix\"\n",
    "]\n",
    "\n",
    "# Padrões que vamos considerar como ruído ou placeholder\n",
    "placeholder_patterns = [\"_______\", \"______\", \"__\", \"!@9#%8\", \"_\", \"__10000__\"]\n",
    "\n",
    "# Substitui por 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    original_unique = df_train[col].unique()\n",
    "    df_train[col] = df_train[col].replace(placeholder_patterns, \"Unknown\")\n",
    "    updated_unique = df_train[col].unique()\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Antes: {original_unique}\")\n",
    "    print(f\"Depois: {updated_unique}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850173a4",
   "metadata": {},
   "source": [
    "## Persistência do Dataset Limpo em `data/processed/`\n",
    "\n",
    "Após conversão de tipos, imputação de valores ausentes e padronização de placeholders, o dataset está pronto para ser salvo em `data/processed/`.  \n",
    "A pasta segue a estrutura **cookiecutter-data-science**, separando dados brutos (`raw/`) de dados prontos para modelagem (`processed/`).  \n",
    "O artefato será versionado com DVC para garantir rastreabilidade integral até o MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19058f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvo em: ../data/processed/train_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: SALVAR DATASET TRATADO EM data/processed/\n",
    "\n",
    "import os\n",
    "\n",
    "# Define caminho coerente\n",
    "processed_dir = \"../data/processed\"  # se seu notebook roda em /notebooks\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Nome do arquivo tratado\n",
    "output_path = os.path.join(processed_dir, \"train_clean.csv\")\n",
    "\n",
    "# Salva CSV limpo\n",
    "df_train.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset salvo em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44381e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in ../data/processed/train_clean.csv |0.00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding ../data/processed/train_clean.c0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /workspace/data/processed0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 12.04file/s]\u001b[A\n",
      "Collecting                                            |4.00 [00:00,  295entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Querying remote cache|█████████████████████|1/1 [00:00<00:00,  4.31files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/0 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mba-mlops-bucket/files/md5'| |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to s3                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/workspace/.dvc/cache/files/md50.00/30.1M [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████|/workspace/.dvc/cache/file30.1M/30.1M [00:00<00:00,     256MB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|██████████|Pushing to s3                     1/1 [00:00<00:00,  7.60file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0mfatal: pathspec 'dvc.yaml' did not match any files\n",
      "[main 6ad2e6e] Versão limpa do dataset treino persistida e versionada com DVC\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/processed/train_clean.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc add ../data/processed/train_clean.csv\n",
    "!dvc push\n",
    "!git add ../data/processed/train_clean.csv.dvc dvc.yaml\n",
    "!git commit -m \"Versão limpa do dataset treino persistida e versionada com DVC\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
