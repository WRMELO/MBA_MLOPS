{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1c384c",
   "metadata": {},
   "source": [
    "## Fase 5 — EDA e Pré-processamento\n",
    "\n",
    "Nesta fase iniciaremos o **Item 5 do Plano de Atividades**, responsável por abrir a etapa de **Análise Exploratória de Dados (EDA)** do conjunto real de dados versionado.  \n",
    "O objetivo é garantir que os arquivos `train.csv` e `test.csv` estejam corretamente estruturados, analisar tipos de variáveis, valores ausentes, estatísticas básicas e possíveis inconsistências.  \n",
    "Todo o trabalho será executado dentro do **DevContainer**, com **rastreabilidade total**, utilizando sempre caminhos relativos revisados fisicamente, em conformidade com o **PROTOCOLO V5.4**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97ed987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD Kernel: /workspace/notebooks\n",
      "Conteúdo de data/raw/: ['test.csv', 'train.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_310944/465301536.py:17: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato treino: (100000, 28)\n",
      "Formato teste: (50000, 27)\n",
      "\n",
      "Tipos de colunas treino:\n",
      "ID                           object\n",
      "Customer_ID                  object\n",
      "Month                        object\n",
      "Name                         object\n",
      "Age                          object\n",
      "SSN                          object\n",
      "Occupation                   object\n",
      "Annual_Income                object\n",
      "Monthly_Inhand_Salary       float64\n",
      "Num_Bank_Accounts             int64\n",
      "Num_Credit_Card               int64\n",
      "Interest_Rate                 int64\n",
      "Num_of_Loan                  object\n",
      "Type_of_Loan                 object\n",
      "Delay_from_due_date           int64\n",
      "Num_of_Delayed_Payment       object\n",
      "Changed_Credit_Limit         object\n",
      "Num_Credit_Inquiries        float64\n",
      "Credit_Mix                   object\n",
      "Outstanding_Debt             object\n",
      "Credit_Utilization_Ratio    float64\n",
      "Credit_History_Age           object\n",
      "Payment_of_Min_Amount        object\n",
      "Total_EMI_per_month         float64\n",
      "Amount_invested_monthly      object\n",
      "Payment_Behaviour            object\n",
      "Monthly_Balance              object\n",
      "Credit_Score                 object\n",
      "dtype: object\n",
      "\n",
      "Valores nulos treino:\n",
      "ID                              0\n",
      "Customer_ID                     0\n",
      "Month                           0\n",
      "Name                         9985\n",
      "Age                             0\n",
      "SSN                             0\n",
      "Occupation                      0\n",
      "Annual_Income                   0\n",
      "Monthly_Inhand_Salary       15002\n",
      "Num_Bank_Accounts               0\n",
      "Num_Credit_Card                 0\n",
      "Interest_Rate                   0\n",
      "Num_of_Loan                     0\n",
      "Type_of_Loan                11408\n",
      "Delay_from_due_date             0\n",
      "Num_of_Delayed_Payment       7002\n",
      "Changed_Credit_Limit            0\n",
      "Num_Credit_Inquiries         1965\n",
      "Credit_Mix                      0\n",
      "Outstanding_Debt                0\n",
      "Credit_Utilization_Ratio        0\n",
      "Credit_History_Age           9030\n",
      "Payment_of_Min_Amount           0\n",
      "Total_EMI_per_month             0\n",
      "Amount_invested_monthly      4479\n",
      "Payment_Behaviour               0\n",
      "Monthly_Balance              1200\n",
      "Credit_Score                    0\n",
      "dtype: int64\n",
      "\n",
      "Amostra treino:\n",
      "        ID Customer_ID     Month             Name   Age          SSN  \\\n",
      "0   0x1602   CUS_0xd40   January    Aaron Maashoh    23  821-00-0265   \n",
      "1   0x1603   CUS_0xd40  February    Aaron Maashoh    23  821-00-0265   \n",
      "2   0x1604   CUS_0xd40     March    Aaron Maashoh  -500  821-00-0265   \n",
      "3   0x1605   CUS_0xd40     April    Aaron Maashoh    23  821-00-0265   \n",
      "4   0x1606   CUS_0xd40       May    Aaron Maashoh    23  821-00-0265   \n",
      "5   0x1607   CUS_0xd40      June    Aaron Maashoh    23  821-00-0265   \n",
      "6   0x1608   CUS_0xd40      July    Aaron Maashoh    23  821-00-0265   \n",
      "7   0x1609   CUS_0xd40    August              NaN    23    #F%$D@*&8   \n",
      "8   0x160e  CUS_0x21b1   January  Rick Rothackerj   28_  004-07-5839   \n",
      "9   0x160f  CUS_0x21b1  February  Rick Rothackerj    28  004-07-5839   \n",
      "10  0x1610  CUS_0x21b1     March  Rick Rothackerj    28  004-07-5839   \n",
      "11  0x1611  CUS_0x21b1     April  Rick Rothackerj    28  004-07-5839   \n",
      "12  0x1612  CUS_0x21b1       May  Rick Rothackerj    28  004-07-5839   \n",
      "13  0x1613  CUS_0x21b1      June  Rick Rothackerj    28  004-07-5839   \n",
      "14  0x1614  CUS_0x21b1      July  Rick Rothackerj    28  004-07-5839   \n",
      "15  0x1615  CUS_0x21b1    August  Rick Rothackerj    28  004-07-5839   \n",
      "16  0x161a  CUS_0x2dbc   January           Langep    34  486-85-3974   \n",
      "17  0x161b  CUS_0x2dbc  February              NaN    34  486-85-3974   \n",
      "18  0x161c  CUS_0x2dbc     March           Langep    34  486-85-3974   \n",
      "19  0x161d  CUS_0x2dbc     April           Langep    34  486-85-3974   \n",
      "\n",
      "   Occupation Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
      "0   Scientist      19114.12            1824.843333                  3  ...   \n",
      "1   Scientist      19114.12                    NaN                  3  ...   \n",
      "2   Scientist      19114.12                    NaN                  3  ...   \n",
      "3   Scientist      19114.12                    NaN                  3  ...   \n",
      "4   Scientist      19114.12            1824.843333                  3  ...   \n",
      "5   Scientist      19114.12                    NaN                  3  ...   \n",
      "6   Scientist      19114.12            1824.843333                  3  ...   \n",
      "7   Scientist      19114.12            1824.843333                  3  ...   \n",
      "8     _______      34847.84            3037.986667                  2  ...   \n",
      "9     Teacher      34847.84            3037.986667                  2  ...   \n",
      "10    Teacher     34847.84_            3037.986667                  2  ...   \n",
      "11    Teacher      34847.84                    NaN                  2  ...   \n",
      "12    Teacher      34847.84            3037.986667                  2  ...   \n",
      "13    Teacher      34847.84            3037.986667                  2  ...   \n",
      "14    Teacher      34847.84                    NaN                  2  ...   \n",
      "15    Teacher      34847.84            3037.986667                  2  ...   \n",
      "16    _______     143162.64           12187.220000                  1  ...   \n",
      "17   Engineer     143162.64           12187.220000                  1  ...   \n",
      "18    _______     143162.64                    NaN                  1  ...   \n",
      "19   Engineer     143162.64           12187.220000                  1  ...   \n",
      "\n",
      "    Credit_Mix  Outstanding_Debt Credit_Utilization_Ratio  \\\n",
      "0            _            809.98                26.822620   \n",
      "1         Good            809.98                31.944960   \n",
      "2         Good            809.98                28.609352   \n",
      "3         Good            809.98                31.377862   \n",
      "4         Good            809.98                24.797347   \n",
      "5         Good            809.98                27.262259   \n",
      "6         Good            809.98                22.537593   \n",
      "7         Good            809.98                23.933795   \n",
      "8         Good            605.03                24.464031   \n",
      "9         Good            605.03                38.550848   \n",
      "10           _            605.03                33.224951   \n",
      "11        Good            605.03                39.182656   \n",
      "12        Good            605.03                34.977895   \n",
      "13        Good            605.03                33.381010   \n",
      "14        Good            605.03                31.131702   \n",
      "15        Good            605.03                32.933856   \n",
      "16        Good           1303.01                28.616735   \n",
      "17        Good           1303.01                41.702573   \n",
      "18        Good           1303.01                26.519815   \n",
      "19           _           1303.01                39.501648   \n",
      "\n",
      "        Credit_History_Age  Payment_of_Min_Amount Total_EMI_per_month  \\\n",
      "0    22 Years and 1 Months                     No           49.574949   \n",
      "1                      NaN                     No           49.574949   \n",
      "2    22 Years and 3 Months                     No           49.574949   \n",
      "3    22 Years and 4 Months                     No           49.574949   \n",
      "4    22 Years and 5 Months                     No           49.574949   \n",
      "5    22 Years and 6 Months                     No           49.574949   \n",
      "6    22 Years and 7 Months                     No           49.574949   \n",
      "7                      NaN                     No           49.574949   \n",
      "8    26 Years and 7 Months                     No           18.816215   \n",
      "9    26 Years and 8 Months                     No           18.816215   \n",
      "10   26 Years and 9 Months                     No           18.816215   \n",
      "11  26 Years and 10 Months                     No           18.816215   \n",
      "12  26 Years and 11 Months                     No           18.816215   \n",
      "13   27 Years and 0 Months                     No           18.816215   \n",
      "14   27 Years and 1 Months                     NM           18.816215   \n",
      "15   27 Years and 2 Months                     No           18.816215   \n",
      "16   17 Years and 9 Months                     No          246.992319   \n",
      "17  17 Years and 10 Months                     No          246.992319   \n",
      "18  17 Years and 11 Months                     No          246.992319   \n",
      "19                     NaN                     No          246.992319   \n",
      "\n",
      "   Amount_invested_monthly                 Payment_Behaviour  \\\n",
      "0        80.41529543900253   High_spent_Small_value_payments   \n",
      "1       118.28022162236736    Low_spent_Large_value_payments   \n",
      "2          81.699521264648   Low_spent_Medium_value_payments   \n",
      "3        199.4580743910713    Low_spent_Small_value_payments   \n",
      "4       41.420153086217326  High_spent_Medium_value_payments   \n",
      "5       62.430172331195294                            !@9#%8   \n",
      "6        178.3440674122349    Low_spent_Small_value_payments   \n",
      "7       24.785216509052056  High_spent_Medium_value_payments   \n",
      "8         104.291825168246    Low_spent_Small_value_payments   \n",
      "9        40.39123782853101   High_spent_Large_value_payments   \n",
      "10       58.51597569589465   High_spent_Large_value_payments   \n",
      "11       99.30622796053305   Low_spent_Medium_value_payments   \n",
      "12      130.11542024292334    Low_spent_Small_value_payments   \n",
      "13      43.477190144355745   High_spent_Large_value_payments   \n",
      "14       70.10177420755677  High_spent_Medium_value_payments   \n",
      "15      218.90434353388733    Low_spent_Small_value_payments   \n",
      "16        168.413702679309                            !@9#%8   \n",
      "17      232.86038375993544   High_spent_Small_value_payments   \n",
      "18               __10000__   High_spent_Small_value_payments   \n",
      "19       825.2162699393922   Low_spent_Medium_value_payments   \n",
      "\n",
      "       Monthly_Balance Credit_Score  \n",
      "0   312.49408867943663         Good  \n",
      "1   284.62916249607184         Good  \n",
      "2    331.2098628537912         Good  \n",
      "3   223.45130972736786         Good  \n",
      "4   341.48923103222177         Good  \n",
      "5    340.4792117872438         Good  \n",
      "6    244.5653167062043         Good  \n",
      "7   358.12416760938714     Standard  \n",
      "8   470.69062692529184     Standard  \n",
      "9    484.5912142650067         Good  \n",
      "10  466.46647639764313     Standard  \n",
      "11   465.6762241330048         Good  \n",
      "12   444.8670318506144         Good  \n",
      "13    481.505261949182         Good  \n",
      "14   464.8806778859809         Good  \n",
      "15  356.07810855965045         Good  \n",
      "16  1043.3159778669492         Good  \n",
      "17   998.8692967863226         Good  \n",
      "18    715.741367403555         Good  \n",
      "19   426.5134106068658         Good  \n",
      "\n",
      "[20 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CARREGAR E INSPECIONAR O DATASET REAL\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Confirma diretório de trabalho do Kernel\n",
    "print(\"CWD Kernel:\", os.getcwd())\n",
    "\n",
    "# Define caminho coerente para o dataset real\n",
    "# Se o notebook estiver dentro de notebooks/, usar ../data/raw/\n",
    "data_raw_dir = \"../data/raw\"\n",
    "\n",
    "# Lista arquivos para validar nomes reais\n",
    "print(\"Conteúdo de data/raw/:\", os.listdir(data_raw_dir))\n",
    "\n",
    "# Carrega arquivos reais versionados\n",
    "df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(data_raw_dir, \"test.csv\"))\n",
    "\n",
    "# Verifica estrutura inicial\n",
    "print(\"Formato treino:\", df_train.shape)\n",
    "print(\"Formato teste:\", df_test.shape)\n",
    "\n",
    "print(\"\\nTipos de colunas treino:\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "print(\"\\nValores nulos treino:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nAmostra treino:\")\n",
    "print(df_train.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50236b0c",
   "metadata": {},
   "source": [
    "## Análise da Célula de Carregamento e Inspeção Inicial\n",
    "\n",
    "A leitura dos arquivos `train.csv` e `test.csv` confirma que o dataset real está estruturado e coerente com o versionamento em `data/raw/`.  \n",
    "O `train.csv` possui **100.000 linhas × 28 colunas** e o `test.csv` **50.000 linhas × 27 colunas**. A listagem do diretório validou os nomes dos arquivos sem dependência de heurística, alinhado ao **PROTOCOLO V5.4**.\n",
    "\n",
    "### Principais observações:\n",
    "\n",
    "- **DtypeWarning:** A leitura acusou tipos mistos em algumas colunas (ex.: coluna 26), indicando registros com strings, símbolos ou formatos inconsistentes em campos que deveriam ser numéricos.\n",
    "- **Tipos de colunas:** Diversas variáveis numéricas (`Age`, `Outstanding_Debt`, `Amount_invested_monthly` etc.) foram lidas como `object`. Isso confirma a necessidade de conversão explícita para tipos numéricos (`int64` ou `float64`) usando coerção.\n",
    "- **Valores ausentes:** A contagem de `NaN` revelou lacunas relevantes em campos como `Name` (~10%), `Monthly_Inhand_Salary` (~15%), `Credit_History_Age` (~9%) e `Num_of_Delayed_Payment`. Será necessário definir políticas de imputação ou descarte.\n",
    "- **Amostra de registros:** Identificou anomalias claras, como `Age` negativo ou inválido (`-500`, `28_`), ocupações `_______` e padrões de ruído como `!@9#%8` em `Payment_Behaviour`. Estes valores precisarão ser tratados na fase de limpeza.\n",
    "\n",
    "Esta análise serve como base para planejar o pré-processamento, garantindo integridade e consistência antes de avançar para treinamento e rastreio de experimentos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa35f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Políticas de Tratamento de Dados — Definição Oficial\n",
    "\n",
    "Com base na análise exploratória inicial e nos requisitos do exercício, definimos as seguintes diretrizes de limpeza e padronização para o dataset `credit-score-classification`. Todas as etapas respeitam o **PROTOCOLO V5.4** e garantem rastreabilidade do pipeline.\n",
    "\n",
    "### 🔹 Conversão de Tipos\n",
    "- Todas as colunas identificadas como `object` mas que representam valores numéricos (ex.: `Age`, `Outstanding_Debt`, `Amount_invested_monthly`) serão convertidas para `float64` usando `pd.to_numeric(errors='coerce')`.  \n",
    "- Valores que não puderem ser convertidos se tornarão `NaN` de forma rastreável.\n",
    "\n",
    "### 🔹 Tratamento de Anomalias Numéricas\n",
    "- Idades negativas ou entradas não numéricas (ex.: `-500`, `28_`) serão convertidas em `NaN` e imputadas com a mediana da coluna `Age`.\n",
    "- Valores absurdos ou placeholders (ex.: `__10000__`) terão caracteres especiais removidos e serão convertidos para número se possível.\n",
    "\n",
    "### 🔹 Valores Ausentes\n",
    "- Variáveis numéricas contínuas com nulos (ex.: `Monthly_Inhand_Salary`, `Credit_History_Age`) serão imputadas com a mediana, pois são menos sensíveis a outliers.\n",
    "- Variáveis categóricas com nulos (ex.: `Occupation`, `Payment_Behaviour`) receberão a categoria `Unknown` para manter integridade sem supor informação.\n",
    "\n",
    "### 🔹 Outliers\n",
    "- Para colunas financeiras como `Annual_Income` e `Outstanding_Debt`, aplicaremos Winsorization limitando os extremos aos percentis 1% e 99% para reduzir impacto de valores distorcidos.\n",
    "\n",
    "### 🔹 Padronização de Strings\n",
    "- Placeholder como `_______` e ruídos do tipo `!@9#%8` serão substituídos por `Unknown`.\n",
    "- Campos com `Yes/No` serão convertidos para padrão binário se necessário na fase de modelagem.\n",
    "\n",
    "### 🔹 Split e Persistência\n",
    "- Após o tratamento, o dataset limpo será salvo em `data/processed/` versionado com DVC, pronto para rastreio no MLflow.\n",
    "- Esta etapa encerra o pré-processamento, mantendo coerência para o treino e serving via API posteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3689d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos originais:\n",
      "Age                        object\n",
      "Annual_Income              object\n",
      "Outstanding_Debt           object\n",
      "Amount_invested_monthly    object\n",
      "Monthly_Balance            object\n",
      "dtype: object\n",
      "\n",
      "Tipos após coerção:\n",
      "Age                        float64\n",
      "Annual_Income              float64\n",
      "Outstanding_Debt           float64\n",
      "Amount_invested_monthly    float64\n",
      "Monthly_Balance            float64\n",
      "dtype: object\n",
      "\n",
      "Valores NaN adicionados por coerção:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CONVERSÃO DE TIPOS NUMÉRICOS COM COERÇÃO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de colunas identificadas como numéricas, mas com tipo object\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: tipos originais\n",
    "print(\"Tipos originais:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Aplica coerção para float64\n",
    "for col in numeric_cols:\n",
    "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "\n",
    "# Depois: tipos convertidos\n",
    "print(\"\\nTipos após coerção:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Verifica quantos valores viraram NaN\n",
    "print(\"\\nValores NaN adicionados por coerção:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cf435",
   "metadata": {},
   "source": [
    "## Imputação de Valores Ausentes — Colunas Numéricas\n",
    "\n",
    "Após converter colunas numéricas para tipos coerentes, aplicamos imputação de `NaN` usando **mediana** para variáveis contínuas.  \n",
    "Esta abordagem é robusta contra distorções de valores extremos, mantém o viés controlado e respeita o histórico real do dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN antes da imputação:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n",
      "Imputado Age com mediana = 33.0\n",
      "Imputado Annual_Income com mediana = 37550.74\n",
      "Imputado Outstanding_Debt com mediana = 1166.37\n",
      "Imputado Amount_invested_monthly com mediana = 128.95453805190283\n",
      "Imputado Monthly_Balance com mediana = 336.73122455696387\n",
      "\n",
      "NaN após imputação:\n",
      "Age                        0\n",
      "Annual_Income              0\n",
      "Outstanding_Debt           0\n",
      "Amount_invested_monthly    0\n",
      "Monthly_Balance            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: IMPUTAR VALORES AUSENTES COM MEDIANA\n",
    "\n",
    "# Define novamente as colunas numéricas que já foram convertidas\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: mostra quantos NaN existem\n",
    "print(\"NaN antes da imputação:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n",
    "\n",
    "# Aplica imputação da mediana, coluna por coluna\n",
    "for col in numeric_cols:\n",
    "    median_value = df_train[col].median()\n",
    "    df_train[col] = df_train[col].fillna(median_value)\n",
    "    print(f\"Imputado {col} com mediana = {median_value}\")\n",
    "\n",
    "# Depois: verifica se ainda restaram NaN\n",
    "print(\"\\nNaN após imputação:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8867",
   "metadata": {},
   "source": [
    "## Limpeza de Placeholders e Ruídos — Colunas Categóricas\n",
    "\n",
    "Após a imputação numérica, iniciamos a padronização de colunas categóricas que apresentam valores placeholders ou símbolos de ruído.  \n",
    "Entradas como `_______`, `______`, `__`, `!@9#%8` e variações similares serão substituídas por `Unknown` para garantir consistência e coerência nos modelos.  \n",
    "Esta abordagem segue o princípio de **não supor valores** quando não há base para inferência.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2da97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coluna: Occupation\n",
      "Antes: ['Scientist' '_______' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "Depois: ['Scientist' 'Unknown' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "\n",
      "Coluna: Payment_Behaviour\n",
      "Antes: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' '!@9#%8'\n",
      " 'High_spent_Large_value_payments']\n",
      "Depois: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' 'Unknown'\n",
      " 'High_spent_Large_value_payments']\n",
      "\n",
      "Coluna: Credit_Mix\n",
      "Antes: ['_' 'Good' 'Standard' 'Bad']\n",
      "Depois: ['Unknown' 'Good' 'Standard' 'Bad']\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: LIMPEZA DE PLACEHOLDERS E RUÍDOS EM CATEGÓRICAS\n",
    "\n",
    "# Lista de colunas categóricas sensíveis a ruído (ajuste conforme necessário)\n",
    "categorical_cols = [\n",
    "    \"Occupation\",\n",
    "    \"Payment_Behaviour\",\n",
    "    \"Credit_Mix\"\n",
    "]\n",
    "\n",
    "# Padrões que vamos considerar como ruído ou placeholder\n",
    "placeholder_patterns = [\"_______\", \"______\", \"__\", \"!@9#%8\", \"_\", \"__10000__\"]\n",
    "\n",
    "# Substitui por 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    original_unique = df_train[col].unique()\n",
    "    df_train[col] = df_train[col].replace(placeholder_patterns, \"Unknown\")\n",
    "    updated_unique = df_train[col].unique()\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Antes: {original_unique}\")\n",
    "    print(f\"Depois: {updated_unique}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850173a4",
   "metadata": {},
   "source": [
    "## Persistência do Dataset Limpo em `data/processed/`\n",
    "\n",
    "Após conversão de tipos, imputação de valores ausentes e padronização de placeholders, o dataset está pronto para ser salvo em `data/processed/`.  \n",
    "A pasta segue a estrutura **cookiecutter-data-science**, separando dados brutos (`raw/`) de dados prontos para modelagem (`processed/`).  \n",
    "O artefato será versionado com DVC para garantir rastreabilidade integral até o MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19058f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvo em: ../data/processed/train_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: SALVAR DATASET TRATADO EM data/processed/\n",
    "\n",
    "import os\n",
    "\n",
    "# Define caminho coerente\n",
    "processed_dir = \"../data/processed\"  # se seu notebook roda em /notebooks\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Nome do arquivo tratado\n",
    "output_path = os.path.join(processed_dir, \"train_clean.csv\")\n",
    "\n",
    "# Salva CSV limpo\n",
    "df_train.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset salvo em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44381e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in ../data/processed/train_clean.csv |0.00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding ../data/processed/train_clean.c0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /workspace/data/processed0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 12.04file/s]\u001b[A\n",
      "Collecting                                            |4.00 [00:00,  295entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Querying remote cache|█████████████████████|1/1 [00:00<00:00,  4.31files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/0 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mba-mlops-bucket/files/md5'| |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to s3                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/workspace/.dvc/cache/files/md50.00/30.1M [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████|/workspace/.dvc/cache/file30.1M/30.1M [00:00<00:00,     256MB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|██████████|Pushing to s3                     1/1 [00:00<00:00,  7.60file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0mfatal: pathspec 'dvc.yaml' did not match any files\n",
      "[main 6ad2e6e] Versão limpa do dataset treino persistida e versionada com DVC\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/processed/train_clean.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc add ../data/processed/train_clean.csv\n",
    "!dvc push\n",
    "!git add ../data/processed/train_clean.csv.dvc dvc.yaml\n",
    "!git commit -m \"Versão limpa do dataset treino persistida e versionada com DVC\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b198a",
   "metadata": {},
   "source": [
    "## Etapa Final — Aplicar Pipeline de Pré-processamento no Conjunto de Teste\n",
    "\n",
    "Para manter consistência, aplicamos **exatamente o mesmo fluxo de tratamento usado no treino**:\n",
    "- Conversão de tipos numéricos com coerção\n",
    "- Imputação de valores ausentes com mediana calculada no treino\n",
    "- Substituição de placeholders e ruídos por `Unknown`\n",
    "- Codificação categórica usando o mesmo esquema de colunas do treino\n",
    "\n",
    "Isso garante que `X_test` terá **as mesmas features** do `X_train` e poderá ser usado sem risco de erro nos experimentos do MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ac9acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputado Age com mediana do treino = 33.0\n",
      "Imputado Annual_Income com mediana do treino = 37550.74\n",
      "Imputado Outstanding_Debt com mediana do treino = 1166.37\n",
      "Imputado Amount_invested_monthly com mediana do treino = 128.95453805190283\n",
      "Imputado Monthly_Balance com mediana do treino = 336.73122455696387\n",
      "Shape final df_test_clean: (50000, 46)\n",
      "Colunas finais: ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance', 'Month_November', 'Month_October', 'Month_September', 'Occupation_Architect', 'Occupation_Developer', 'Occupation_Doctor', 'Occupation_Engineer', 'Occupation_Entrepreneur', 'Occupation_Journalist', 'Occupation_Lawyer', 'Occupation_Manager', 'Occupation_Mechanic', 'Occupation_Media_Manager', 'Occupation_Musician', 'Occupation_Scientist', 'Occupation_Teacher', 'Occupation_Unknown', 'Occupation_Writer', 'Credit_Mix_Good', 'Credit_Mix_Standard', 'Credit_Mix_Unknown', 'Payment_Behaviour_High_spent_Medium_value_payments', 'Payment_Behaviour_High_spent_Small_value_payments', 'Payment_Behaviour_Low_spent_Large_value_payments', 'Payment_Behaviour_Low_spent_Medium_value_payments', 'Payment_Behaviour_Low_spent_Small_value_payments', 'Payment_Behaviour_Unknown']\n"
     ]
    }
   ],
   "source": [
    "# ETAPA FINAL: TRATAR CONJUNTO DE TESTE COM MESMA LÓGICA DO TREINO\n",
    "\n",
    "# Copia test bruto\n",
    "df_test_clean = df_test.copy()\n",
    "\n",
    "# --- Conversão de tipos numéricos ---\n",
    "numeric_cols = [\"Age\", \"Annual_Income\", \"Outstanding_Debt\", \n",
    "                \"Amount_invested_monthly\", \"Monthly_Balance\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df_test_clean[col] = pd.to_numeric(df_test_clean[col], errors='coerce')\n",
    "\n",
    "# --- Imputação de valores ausentes com mediana calculada no treino ---\n",
    "for col in numeric_cols:\n",
    "    median_value = df_train[col].median()\n",
    "    df_test_clean[col] = df_test_clean[col].fillna(median_value)\n",
    "    print(f\"Imputado {col} com mediana do treino = {median_value}\")\n",
    "\n",
    "# --- Limpeza de placeholders/ruídos ---\n",
    "categorical_cols = [\"Occupation\", \"Payment_Behaviour\", \"Credit_Mix\"]\n",
    "placeholder_patterns = [\"_______\", \"______\", \"__\", \"!@9#%8\", \"_\", \"__10000__\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_test_clean[col] = df_test_clean[col].replace(placeholder_patterns, \"Unknown\")\n",
    "\n",
    "# --- Drop de colunas ID-only ---\n",
    "cols_to_drop = [\"ID\", \"Customer_ID\", \"Name\", \"SSN\"]\n",
    "df_test_clean = df_test_clean.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- Codificação one-hot coerente ---\n",
    "df_test_clean = pd.get_dummies(df_test_clean, columns=[\"Month\", \"Occupation\", \n",
    "                                                       \"Credit_Mix\", \"Payment_Behaviour\"],\n",
    "                               drop_first=True)\n",
    "\n",
    "print(\"Shape final df_test_clean:\", df_test_clean.shape)\n",
    "print(\"Colunas finais:\", df_test_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faca7f1",
   "metadata": {},
   "source": [
    "##  Persistência do Conjunto de Teste no `processed`\n",
    "\n",
    "Após aplicar todo o pipeline de pré-processamento coerente com o treino, o conjunto de teste será salvo em `data/processed/`.  \n",
    "Este arquivo garante que o `X_test` final terá as mesmas transformações do `X_train`, ficando pronto para experimentos no MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e39f9311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: /workspace/data/processed/test_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA FINAL: SALVAR TESTE TRATADO EM /workspace/data/processed/\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Força caminho base coerente (mesmo que rode em /workspace/notebooks)\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    processed_dir = cwd.parent / \"data\" / \"processed\"\n",
    "else:\n",
    "    processed_dir = cwd / \"data\" / \"processed\"\n",
    "\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Caminho final padronizado: test_clean.csv\n",
    "test_clean_path = processed_dir / \"test_clean.csv\"\n",
    "\n",
    "# Salva CSV limpo\n",
    "df_test_clean.to_csv(test_clean_path, index=False)\n",
    "\n",
    "print(f\"Arquivo salvo em: {test_clean_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8287c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD Kernel: /workspace/notebooks\n",
      "Caminho usado no dvc add: ../data/processed/test_clean.csv\n",
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in ../data/processed/test_clean.csv |0.00 \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding ../data/processed/test_clean.cs0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /workspace/data/processed0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 19.59file/s]\u001b[A\n",
      "Collecting                                            |5.00 [00:00,  321entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Querying remote cache|█████████████████████|1/1 [00:00<00:00,  4.11files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/0 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mba-mlops-bucket/files/md5'| |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to s3                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/workspace/.dvc/cache/files/md50.00/17.9M [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0m[main 2750532] Adiciona test_clean.csv versionado na camada processed\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/processed/test_clean.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "# ETAPA ÚNICA: CONFERE CWD, AJUSTA CAMINHO E VERSIONA test_clean.csv CORRETAMENTE\n",
    "\n",
    "import os\n",
    "\n",
    "# 1) Confirma onde o Kernel está rodando\n",
    "cwd = os.getcwd()\n",
    "print(f\"CWD Kernel: {cwd}\")\n",
    "\n",
    "# 2) Define caminho relativo coerente\n",
    "if cwd.endswith(\"notebooks\"):\n",
    "    path_to_file = \"../data/processed/test_clean.csv\"\n",
    "    path_to_dvc = \"../data/processed/test_clean.csv.dvc\"\n",
    "else:\n",
    "    path_to_file = \"data/processed/test_clean.csv\"\n",
    "    path_to_dvc = \"data/processed/test_clean.csv.dvc\"\n",
    "\n",
    "print(f\"Caminho usado no dvc add: {path_to_file}\")\n",
    "\n",
    "# 3) Executa shell no Jupyter usando !\n",
    "!dvc add {path_to_file}\n",
    "!dvc push\n",
    "!git add {path_to_dvc}\n",
    "!git commit -m \"Adiciona test_clean.csv versionado na camada processed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb31c2",
   "metadata": {},
   "source": [
    "---\n",
    "REFATORAMENTO DO CLEAN.CSV\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed88e9",
   "metadata": {},
   "source": [
    "## ETAPA: PADRÃO DE CURADORIA — RAW ➜ CLEAN V1\n",
    "\n",
    "Aplicamos o mesmo pipeline de curadoria para `RAW TRAIN` e `RAW TEST`:\n",
    "\n",
    "1️⃣ Remoção de colunas identificadoras: `ID`, `Customer_ID`, `Name`, `SSN`.  \n",
    "2️⃣ Substituição de placeholders: `'Unknown'`, `'_______'`, `'!@9#%8'`, `'#F%$D@*&8'` ➜ `Other`.  \n",
    "3️⃣ Coerção de tipos para colunas numéricas (`Age`, `Annual_Income`, `Monthly_Inhand_Salary`, `Changed_Credit_Limit`, `Outstanding_Debt` etc.).  \n",
    "4️⃣ Correção de outliers lógicos (ex: `Age` < 0 ➜ `NaN`, `Num_Bank_Accounts` = -1 ➜ 0).  \n",
    "5️⃣ Imputação de `NaN` para numéricas usando **mediana agrupada por `Occupation`**, com fallback para mediana global.\n",
    "6️⃣ Imputação de `Occupation` ausente com moda.\n",
    "7️⃣ Nenhuma codificação `get_dummies` neste estágio — `Occupation` permanece nominal.\n",
    "8️⃣ Salvo como `train_clean_v1.csv` e `test_clean_v1.csv`.\n",
    "9️⃣ Versionamento DVC para rastreabilidade.\n",
    "\n",
    "Todo o fluxo rastreado no **PROTOCOLO V5.4**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbaccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77546/3315925519.py:10: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(TRAIN_RAW_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAW TRAIN shape: (100000, 28)\n",
      "✅ RAW TEST shape: (50000, 27)\n",
      "✅ TRAIN CLEAN V1: (100000, 24)\n",
      "✅ TEST CLEAN V1: (50000, 23)\n",
      "\n",
      "🔍 Preview TRAIN CLEAN V1:\n",
      "      Month   Age Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
      "0   January  23.0  Scientist       19114.12            1824.843333   \n",
      "1  February  23.0  Scientist       19114.12            3260.465000   \n",
      "2     March  33.0  Scientist       19114.12            3260.465000   \n",
      "3     April  23.0  Scientist       19114.12            3260.465000   \n",
      "4       May  23.0  Scientist       19114.12            1824.843333   \n",
      "\n",
      "   Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
      "0                  3                4              3          4.0   \n",
      "1                  3                4              3          4.0   \n",
      "2                  3                4              3          4.0   \n",
      "3                  3                4              3          4.0   \n",
      "4                  3                4              3          4.0   \n",
      "\n",
      "                                        Type_of_Loan  ...  Credit_Mix  \\\n",
      "0  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...           _   \n",
      "1  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "2  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "3  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "4  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "\n",
      "   Outstanding_Debt  Credit_Utilization_Ratio     Credit_History_Age  \\\n",
      "0            809.98                 26.822620  22 Years and 1 Months   \n",
      "1            809.98                 31.944960                    NaN   \n",
      "2            809.98                 28.609352  22 Years and 3 Months   \n",
      "3            809.98                 31.377862  22 Years and 4 Months   \n",
      "4            809.98                 24.797347  22 Years and 5 Months   \n",
      "\n",
      "  Payment_of_Min_Amount  Total_EMI_per_month  Amount_invested_monthly  \\\n",
      "0                    No            49.574949        80.41529543900253   \n",
      "1                    No            49.574949       118.28022162236736   \n",
      "2                    No            49.574949          81.699521264648   \n",
      "3                    No            49.574949        199.4580743910713   \n",
      "4                    No            49.574949       41.420153086217326   \n",
      "\n",
      "                  Payment_Behaviour     Monthly_Balance  Credit_Score  \n",
      "0   High_spent_Small_value_payments  312.49408867943663          Good  \n",
      "1    Low_spent_Large_value_payments  284.62916249607184          Good  \n",
      "2   Low_spent_Medium_value_payments   331.2098628537912          Good  \n",
      "3    Low_spent_Small_value_payments  223.45130972736786          Good  \n",
      "4  High_spent_Medium_value_payments  341.48923103222177          Good  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "🔍 Preview TEST CLEAN V1:\n",
      "       Month   Age Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
      "0  September  23.0  Scientist       19114.12            1824.843333   \n",
      "1    October  24.0  Scientist       19114.12            1824.843333   \n",
      "2   November  24.0  Scientist       19114.12            1824.843333   \n",
      "3   December  34.0  Scientist       19114.12            3260.465000   \n",
      "4  September  28.0      Other       34847.84            3037.986667   \n",
      "\n",
      "   Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
      "0                  3                4              3          4.0   \n",
      "1                  3                4              3          4.0   \n",
      "2                  3                4              3          4.0   \n",
      "3                  3                4              3          4.0   \n",
      "4                  2                4              6          1.0   \n",
      "\n",
      "                                        Type_of_Loan  ...  \\\n",
      "0  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "1  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "2  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "3  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "4                                Credit-Builder Loan  ...   \n",
      "\n",
      "   Num_Credit_Inquiries  Credit_Mix  Outstanding_Debt  \\\n",
      "0                2022.0        Good            809.98   \n",
      "1                   4.0        Good            809.98   \n",
      "2                   4.0        Good            809.98   \n",
      "3                   4.0        Good            809.98   \n",
      "4                   5.0        Good            605.03   \n",
      "\n",
      "   Credit_Utilization_Ratio      Credit_History_Age  Payment_of_Min_Amount  \\\n",
      "0                 35.030402   22 Years and 9 Months                     No   \n",
      "1                 33.053114  22 Years and 10 Months                     No   \n",
      "2                 33.811894                     NaN                     No   \n",
      "3                 32.430559   23 Years and 0 Months                     No   \n",
      "4                 25.926822   27 Years and 3 Months                     No   \n",
      "\n",
      "   Total_EMI_per_month Amount_invested_monthly  \\\n",
      "0            49.574949      236.64268203272135   \n",
      "1            49.574949      21.465380264657146   \n",
      "2            49.574949      148.23393788500925   \n",
      "3            49.574949       39.08251089460281   \n",
      "4            18.816215      39.684018417945296   \n",
      "\n",
      "                  Payment_Behaviour     Monthly_Balance  \n",
      "0    Low_spent_Small_value_payments  186.26670208571772  \n",
      "1  High_spent_Medium_value_payments  361.44400385378196  \n",
      "2   Low_spent_Medium_value_payments  264.67544623342997  \n",
      "3  High_spent_Medium_value_payments  343.82687322383634  \n",
      "4   High_spent_Large_value_payments   485.2984336755923  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "✅ Arquivos salvos: train_clean_v1.csv & test_clean_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: PADRÃO CURADORIA RAW ➜ CLEAN V1 (TRAIN & TEST)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ⚙️ Caminhos\n",
    "TRAIN_RAW_PATH = '../data/raw/train.csv'\n",
    "TEST_RAW_PATH  = '../data/raw/test.csv'\n",
    "\n",
    "# 1️⃣ Carrega\n",
    "df_train = pd.read_csv(TRAIN_RAW_PATH)\n",
    "df_test  = pd.read_csv(TEST_RAW_PATH)\n",
    "\n",
    "print(f\"✅ RAW TRAIN shape: {df_train.shape}\")\n",
    "print(f\"✅ RAW TEST shape: {df_test.shape}\")\n",
    "\n",
    "# 2️⃣ Função padrão\n",
    "def clean_pipeline(df):\n",
    "    # Remove IDs\n",
    "    drop_cols = ['ID', 'Customer_ID', 'Name', 'SSN']\n",
    "    df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True, errors='ignore')\n",
    "\n",
    "    # Substitui placeholders\n",
    "    placeholders = ['Unknown', '_______', '!@9#%8', '#F%$D@*&8']\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].replace(placeholders, 'Other')\n",
    "\n",
    "    # Coerção numérica e correção de outliers\n",
    "    numeric_cols = ['Annual_Income', 'Monthly_Inhand_Salary', 'Changed_Credit_Limit', \n",
    "                    'Outstanding_Debt', 'Age', 'Num_Bank_Accounts', \n",
    "                    'Num_of_Loan', 'Num_of_Delayed_Payment']\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    if 'Age' in df.columns:\n",
    "        df.loc[df['Age'] < 0, 'Age'] = pd.NA\n",
    "\n",
    "    if 'Num_Bank_Accounts' in df.columns:\n",
    "        df.loc[df['Num_Bank_Accounts'] < 0, 'Num_Bank_Accounts'] = 0\n",
    "\n",
    "    # Imputação por Occupation se existir\n",
    "    for col in ['Annual_Income', 'Monthly_Inhand_Salary', 'Changed_Credit_Limit',\n",
    "                'Outstanding_Debt', 'Num_of_Loan', 'Num_of_Delayed_Payment']:\n",
    "        if col in df.columns:\n",
    "            if 'Occupation' in df.columns:\n",
    "                df[col] = df.groupby('Occupation')[col].transform(\n",
    "                    lambda x: x.fillna(x.median())\n",
    "                )\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    if 'Age' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    if 'Num_Bank_Accounts' in df.columns:\n",
    "        df['Num_Bank_Accounts'] = df['Num_Bank_Accounts'].fillna(df['Num_Bank_Accounts'].median())\n",
    "\n",
    "    # Imputa Occupation com moda\n",
    "    if 'Occupation' in df.columns:\n",
    "        df['Occupation'] = df['Occupation'].fillna(df['Occupation'].mode()[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 3️⃣ Aplica\n",
    "df_train_clean = clean_pipeline(df_train)\n",
    "df_test_clean  = clean_pipeline(df_test)\n",
    "\n",
    "print(f\"✅ TRAIN CLEAN V1: {df_train_clean.shape}\")\n",
    "print(f\"✅ TEST CLEAN V1: {df_test_clean.shape}\")\n",
    "\n",
    "print(\"\\n🔍 Preview TRAIN CLEAN V1:\")\n",
    "print(df_train_clean.head(5))\n",
    "\n",
    "print(\"\\n🔍 Preview TEST CLEAN V1:\")\n",
    "print(df_test_clean.head(5))\n",
    "\n",
    "# 4️⃣ Salva\n",
    "df_train_clean.to_csv('../data/processed/train_clean_v1.csv', index=False)\n",
    "df_test_clean.to_csv('../data/processed/test_clean_v1.csv', index=False)\n",
    "print(\"\\n✅ Arquivos salvos: train_clean_v1.csv & test_clean_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e2bc6",
   "metadata": {},
   "source": [
    "# ✅ STATUS FINAL — TRAIN & TEST CLEAN V1\n",
    "\n",
    "- Todos os passos de curadoria foram reaplicados a partir dos datasets `RAW`.\n",
    "- Remoção de identificadores, coerção de tipos, placeholders padronizados.\n",
    "- Imputação por `Occupation` mantida, sem codificação antecipada.\n",
    "- `Credit_Score` presente apenas no `TRAIN` (24 colunas); ausente no `TEST` (23 colunas) — coerente com ML supervisionado.\n",
    "- Ambos versionados como `*_v1.csv`, prontos para rastreio via DVC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215dcfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l⠋ Checking graph\n",
      "\u001b[?25l⠋ Checking graph\n",
      "\u001b[?25h\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ dvc add concluído.\n",
      "2 files pushed\n",
      "\n",
      "✅ dvc push concluído. Ambos os arquivos estão versionados no remote.\n"
     ]
    }
   ],
   "source": [
    "# 🔧 ETAPA: VERSIONAMENTO VIA DVC NO JUPYTER — CLEAN V1\n",
    "\n",
    "\"\"\"\n",
    "1️⃣ Adiciona os arquivos ao DVC tracking.\n",
    "2️⃣ Executa o push para o remote (ex: MinIO).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Caminhos coerentes\n",
    "TRAIN_CLEAN_V1 = '../data/processed/train_clean_v1.csv'\n",
    "TEST_CLEAN_V1 = '../data/processed/test_clean_v1.csv'\n",
    "\n",
    "# 1️⃣ dvc add\n",
    "os.system(f'dvc add {TRAIN_CLEAN_V1}')\n",
    "os.system(f'dvc add {TEST_CLEAN_V1}')\n",
    "\n",
    "print(\"\\n✅ dvc add concluído.\")\n",
    "\n",
    "# 2️⃣ dvc push\n",
    "os.system('dvc push')\n",
    "\n",
    "print(\"\\n✅ dvc push concluído. Ambos os arquivos estão versionados no remote.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404796f7",
   "metadata": {},
   "source": [
    "## ETAPA CONCLUÍDA — CURADORIA RAW ➜ CLEAN V1\n",
    "\n",
    "- Finalizamos a nova camada `CLEAN V1` usando pipeline padronizado, aplicando coerção de tipos, substituição de placeholders e imputação por grupo `Occupation`.\n",
    "- O kernel anterior estourava por cardinalidade descontrolada em colunas como `Type_of_Loan`, `Payment_Behaviour`, etc.\n",
    "- A partir deste ponto, a análise de cardinalidade será refeita **sobre `TRAIN_CLEAN_V1` e `TEST_CLEAN_V1`**, e não sobre a versão anterior.\n",
    "- O Feature Engineering segue no notebook `feature_engineering_curadoria.ipynb` com blocos autocontidos e sem ícones, mantendo rastreabilidade PROTOCOLO V5.4.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
