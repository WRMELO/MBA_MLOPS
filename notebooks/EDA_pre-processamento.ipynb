{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1c384c",
   "metadata": {},
   "source": [
    "## Fase 5 ‚Äî EDA e Pr√©-processamento\n",
    "\n",
    "Nesta fase iniciaremos o **Item 5 do Plano de Atividades**, respons√°vel por abrir a etapa de **An√°lise Explorat√≥ria de Dados (EDA)** do conjunto real de dados versionado.  \n",
    "O objetivo √© garantir que os arquivos `train.csv` e `test.csv` estejam corretamente estruturados, analisar tipos de vari√°veis, valores ausentes, estat√≠sticas b√°sicas e poss√≠veis inconsist√™ncias.  \n",
    "Todo o trabalho ser√° executado dentro do **DevContainer**, com **rastreabilidade total**, utilizando sempre caminhos relativos revisados fisicamente, em conformidade com o **PROTOCOLO V5.4**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97ed987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD Kernel: /workspace/notebooks\n",
      "Conte√∫do de data/raw/: ['test.csv', 'train.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_310944/465301536.py:17: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato treino: (100000, 28)\n",
      "Formato teste: (50000, 27)\n",
      "\n",
      "Tipos de colunas treino:\n",
      "ID                           object\n",
      "Customer_ID                  object\n",
      "Month                        object\n",
      "Name                         object\n",
      "Age                          object\n",
      "SSN                          object\n",
      "Occupation                   object\n",
      "Annual_Income                object\n",
      "Monthly_Inhand_Salary       float64\n",
      "Num_Bank_Accounts             int64\n",
      "Num_Credit_Card               int64\n",
      "Interest_Rate                 int64\n",
      "Num_of_Loan                  object\n",
      "Type_of_Loan                 object\n",
      "Delay_from_due_date           int64\n",
      "Num_of_Delayed_Payment       object\n",
      "Changed_Credit_Limit         object\n",
      "Num_Credit_Inquiries        float64\n",
      "Credit_Mix                   object\n",
      "Outstanding_Debt             object\n",
      "Credit_Utilization_Ratio    float64\n",
      "Credit_History_Age           object\n",
      "Payment_of_Min_Amount        object\n",
      "Total_EMI_per_month         float64\n",
      "Amount_invested_monthly      object\n",
      "Payment_Behaviour            object\n",
      "Monthly_Balance              object\n",
      "Credit_Score                 object\n",
      "dtype: object\n",
      "\n",
      "Valores nulos treino:\n",
      "ID                              0\n",
      "Customer_ID                     0\n",
      "Month                           0\n",
      "Name                         9985\n",
      "Age                             0\n",
      "SSN                             0\n",
      "Occupation                      0\n",
      "Annual_Income                   0\n",
      "Monthly_Inhand_Salary       15002\n",
      "Num_Bank_Accounts               0\n",
      "Num_Credit_Card                 0\n",
      "Interest_Rate                   0\n",
      "Num_of_Loan                     0\n",
      "Type_of_Loan                11408\n",
      "Delay_from_due_date             0\n",
      "Num_of_Delayed_Payment       7002\n",
      "Changed_Credit_Limit            0\n",
      "Num_Credit_Inquiries         1965\n",
      "Credit_Mix                      0\n",
      "Outstanding_Debt                0\n",
      "Credit_Utilization_Ratio        0\n",
      "Credit_History_Age           9030\n",
      "Payment_of_Min_Amount           0\n",
      "Total_EMI_per_month             0\n",
      "Amount_invested_monthly      4479\n",
      "Payment_Behaviour               0\n",
      "Monthly_Balance              1200\n",
      "Credit_Score                    0\n",
      "dtype: int64\n",
      "\n",
      "Amostra treino:\n",
      "        ID Customer_ID     Month             Name   Age          SSN  \\\n",
      "0   0x1602   CUS_0xd40   January    Aaron Maashoh    23  821-00-0265   \n",
      "1   0x1603   CUS_0xd40  February    Aaron Maashoh    23  821-00-0265   \n",
      "2   0x1604   CUS_0xd40     March    Aaron Maashoh  -500  821-00-0265   \n",
      "3   0x1605   CUS_0xd40     April    Aaron Maashoh    23  821-00-0265   \n",
      "4   0x1606   CUS_0xd40       May    Aaron Maashoh    23  821-00-0265   \n",
      "5   0x1607   CUS_0xd40      June    Aaron Maashoh    23  821-00-0265   \n",
      "6   0x1608   CUS_0xd40      July    Aaron Maashoh    23  821-00-0265   \n",
      "7   0x1609   CUS_0xd40    August              NaN    23    #F%$D@*&8   \n",
      "8   0x160e  CUS_0x21b1   January  Rick Rothackerj   28_  004-07-5839   \n",
      "9   0x160f  CUS_0x21b1  February  Rick Rothackerj    28  004-07-5839   \n",
      "10  0x1610  CUS_0x21b1     March  Rick Rothackerj    28  004-07-5839   \n",
      "11  0x1611  CUS_0x21b1     April  Rick Rothackerj    28  004-07-5839   \n",
      "12  0x1612  CUS_0x21b1       May  Rick Rothackerj    28  004-07-5839   \n",
      "13  0x1613  CUS_0x21b1      June  Rick Rothackerj    28  004-07-5839   \n",
      "14  0x1614  CUS_0x21b1      July  Rick Rothackerj    28  004-07-5839   \n",
      "15  0x1615  CUS_0x21b1    August  Rick Rothackerj    28  004-07-5839   \n",
      "16  0x161a  CUS_0x2dbc   January           Langep    34  486-85-3974   \n",
      "17  0x161b  CUS_0x2dbc  February              NaN    34  486-85-3974   \n",
      "18  0x161c  CUS_0x2dbc     March           Langep    34  486-85-3974   \n",
      "19  0x161d  CUS_0x2dbc     April           Langep    34  486-85-3974   \n",
      "\n",
      "   Occupation Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
      "0   Scientist      19114.12            1824.843333                  3  ...   \n",
      "1   Scientist      19114.12                    NaN                  3  ...   \n",
      "2   Scientist      19114.12                    NaN                  3  ...   \n",
      "3   Scientist      19114.12                    NaN                  3  ...   \n",
      "4   Scientist      19114.12            1824.843333                  3  ...   \n",
      "5   Scientist      19114.12                    NaN                  3  ...   \n",
      "6   Scientist      19114.12            1824.843333                  3  ...   \n",
      "7   Scientist      19114.12            1824.843333                  3  ...   \n",
      "8     _______      34847.84            3037.986667                  2  ...   \n",
      "9     Teacher      34847.84            3037.986667                  2  ...   \n",
      "10    Teacher     34847.84_            3037.986667                  2  ...   \n",
      "11    Teacher      34847.84                    NaN                  2  ...   \n",
      "12    Teacher      34847.84            3037.986667                  2  ...   \n",
      "13    Teacher      34847.84            3037.986667                  2  ...   \n",
      "14    Teacher      34847.84                    NaN                  2  ...   \n",
      "15    Teacher      34847.84            3037.986667                  2  ...   \n",
      "16    _______     143162.64           12187.220000                  1  ...   \n",
      "17   Engineer     143162.64           12187.220000                  1  ...   \n",
      "18    _______     143162.64                    NaN                  1  ...   \n",
      "19   Engineer     143162.64           12187.220000                  1  ...   \n",
      "\n",
      "    Credit_Mix  Outstanding_Debt Credit_Utilization_Ratio  \\\n",
      "0            _            809.98                26.822620   \n",
      "1         Good            809.98                31.944960   \n",
      "2         Good            809.98                28.609352   \n",
      "3         Good            809.98                31.377862   \n",
      "4         Good            809.98                24.797347   \n",
      "5         Good            809.98                27.262259   \n",
      "6         Good            809.98                22.537593   \n",
      "7         Good            809.98                23.933795   \n",
      "8         Good            605.03                24.464031   \n",
      "9         Good            605.03                38.550848   \n",
      "10           _            605.03                33.224951   \n",
      "11        Good            605.03                39.182656   \n",
      "12        Good            605.03                34.977895   \n",
      "13        Good            605.03                33.381010   \n",
      "14        Good            605.03                31.131702   \n",
      "15        Good            605.03                32.933856   \n",
      "16        Good           1303.01                28.616735   \n",
      "17        Good           1303.01                41.702573   \n",
      "18        Good           1303.01                26.519815   \n",
      "19           _           1303.01                39.501648   \n",
      "\n",
      "        Credit_History_Age  Payment_of_Min_Amount Total_EMI_per_month  \\\n",
      "0    22 Years and 1 Months                     No           49.574949   \n",
      "1                      NaN                     No           49.574949   \n",
      "2    22 Years and 3 Months                     No           49.574949   \n",
      "3    22 Years and 4 Months                     No           49.574949   \n",
      "4    22 Years and 5 Months                     No           49.574949   \n",
      "5    22 Years and 6 Months                     No           49.574949   \n",
      "6    22 Years and 7 Months                     No           49.574949   \n",
      "7                      NaN                     No           49.574949   \n",
      "8    26 Years and 7 Months                     No           18.816215   \n",
      "9    26 Years and 8 Months                     No           18.816215   \n",
      "10   26 Years and 9 Months                     No           18.816215   \n",
      "11  26 Years and 10 Months                     No           18.816215   \n",
      "12  26 Years and 11 Months                     No           18.816215   \n",
      "13   27 Years and 0 Months                     No           18.816215   \n",
      "14   27 Years and 1 Months                     NM           18.816215   \n",
      "15   27 Years and 2 Months                     No           18.816215   \n",
      "16   17 Years and 9 Months                     No          246.992319   \n",
      "17  17 Years and 10 Months                     No          246.992319   \n",
      "18  17 Years and 11 Months                     No          246.992319   \n",
      "19                     NaN                     No          246.992319   \n",
      "\n",
      "   Amount_invested_monthly                 Payment_Behaviour  \\\n",
      "0        80.41529543900253   High_spent_Small_value_payments   \n",
      "1       118.28022162236736    Low_spent_Large_value_payments   \n",
      "2          81.699521264648   Low_spent_Medium_value_payments   \n",
      "3        199.4580743910713    Low_spent_Small_value_payments   \n",
      "4       41.420153086217326  High_spent_Medium_value_payments   \n",
      "5       62.430172331195294                            !@9#%8   \n",
      "6        178.3440674122349    Low_spent_Small_value_payments   \n",
      "7       24.785216509052056  High_spent_Medium_value_payments   \n",
      "8         104.291825168246    Low_spent_Small_value_payments   \n",
      "9        40.39123782853101   High_spent_Large_value_payments   \n",
      "10       58.51597569589465   High_spent_Large_value_payments   \n",
      "11       99.30622796053305   Low_spent_Medium_value_payments   \n",
      "12      130.11542024292334    Low_spent_Small_value_payments   \n",
      "13      43.477190144355745   High_spent_Large_value_payments   \n",
      "14       70.10177420755677  High_spent_Medium_value_payments   \n",
      "15      218.90434353388733    Low_spent_Small_value_payments   \n",
      "16        168.413702679309                            !@9#%8   \n",
      "17      232.86038375993544   High_spent_Small_value_payments   \n",
      "18               __10000__   High_spent_Small_value_payments   \n",
      "19       825.2162699393922   Low_spent_Medium_value_payments   \n",
      "\n",
      "       Monthly_Balance Credit_Score  \n",
      "0   312.49408867943663         Good  \n",
      "1   284.62916249607184         Good  \n",
      "2    331.2098628537912         Good  \n",
      "3   223.45130972736786         Good  \n",
      "4   341.48923103222177         Good  \n",
      "5    340.4792117872438         Good  \n",
      "6    244.5653167062043         Good  \n",
      "7   358.12416760938714     Standard  \n",
      "8   470.69062692529184     Standard  \n",
      "9    484.5912142650067         Good  \n",
      "10  466.46647639764313     Standard  \n",
      "11   465.6762241330048         Good  \n",
      "12   444.8670318506144         Good  \n",
      "13    481.505261949182         Good  \n",
      "14   464.8806778859809         Good  \n",
      "15  356.07810855965045         Good  \n",
      "16  1043.3159778669492         Good  \n",
      "17   998.8692967863226         Good  \n",
      "18    715.741367403555         Good  \n",
      "19   426.5134106068658         Good  \n",
      "\n",
      "[20 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CARREGAR E INSPECIONAR O DATASET REAL\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Confirma diret√≥rio de trabalho do Kernel\n",
    "print(\"CWD Kernel:\", os.getcwd())\n",
    "\n",
    "# Define caminho coerente para o dataset real\n",
    "# Se o notebook estiver dentro de notebooks/, usar ../data/raw/\n",
    "data_raw_dir = \"../data/raw\"\n",
    "\n",
    "# Lista arquivos para validar nomes reais\n",
    "print(\"Conte√∫do de data/raw/:\", os.listdir(data_raw_dir))\n",
    "\n",
    "# Carrega arquivos reais versionados\n",
    "df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(data_raw_dir, \"test.csv\"))\n",
    "\n",
    "# Verifica estrutura inicial\n",
    "print(\"Formato treino:\", df_train.shape)\n",
    "print(\"Formato teste:\", df_test.shape)\n",
    "\n",
    "print(\"\\nTipos de colunas treino:\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "print(\"\\nValores nulos treino:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nAmostra treino:\")\n",
    "print(df_train.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50236b0c",
   "metadata": {},
   "source": [
    "## An√°lise da C√©lula de Carregamento e Inspe√ß√£o Inicial\n",
    "\n",
    "A leitura dos arquivos `train.csv` e `test.csv` confirma que o dataset real est√° estruturado e coerente com o versionamento em `data/raw/`.  \n",
    "O `train.csv` possui **100.000 linhas √ó 28 colunas** e o `test.csv` **50.000 linhas √ó 27 colunas**. A listagem do diret√≥rio validou os nomes dos arquivos sem depend√™ncia de heur√≠stica, alinhado ao **PROTOCOLO V5.4**.\n",
    "\n",
    "### Principais observa√ß√µes:\n",
    "\n",
    "- **DtypeWarning:** A leitura acusou tipos mistos em algumas colunas (ex.: coluna 26), indicando registros com strings, s√≠mbolos ou formatos inconsistentes em campos que deveriam ser num√©ricos.\n",
    "- **Tipos de colunas:** Diversas vari√°veis num√©ricas (`Age`, `Outstanding_Debt`, `Amount_invested_monthly` etc.) foram lidas como `object`. Isso confirma a necessidade de convers√£o expl√≠cita para tipos num√©ricos (`int64` ou `float64`) usando coer√ß√£o.\n",
    "- **Valores ausentes:** A contagem de `NaN` revelou lacunas relevantes em campos como `Name` (~10%), `Monthly_Inhand_Salary` (~15%), `Credit_History_Age` (~9%) e `Num_of_Delayed_Payment`. Ser√° necess√°rio definir pol√≠ticas de imputa√ß√£o ou descarte.\n",
    "- **Amostra de registros:** Identificou anomalias claras, como `Age` negativo ou inv√°lido (`-500`, `28_`), ocupa√ß√µes `_______` e padr√µes de ru√≠do como `!@9#%8` em `Payment_Behaviour`. Estes valores precisar√£o ser tratados na fase de limpeza.\n",
    "\n",
    "Esta an√°lise serve como base para planejar o pr√©-processamento, garantindo integridade e consist√™ncia antes de avan√ßar para treinamento e rastreio de experimentos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa35f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Pol√≠ticas de Tratamento de Dados ‚Äî Defini√ß√£o Oficial\n",
    "\n",
    "Com base na an√°lise explorat√≥ria inicial e nos requisitos do exerc√≠cio, definimos as seguintes diretrizes de limpeza e padroniza√ß√£o para o dataset `credit-score-classification`. Todas as etapas respeitam o **PROTOCOLO V5.4** e garantem rastreabilidade do pipeline.\n",
    "\n",
    "### üîπ Convers√£o de Tipos\n",
    "- Todas as colunas identificadas como `object` mas que representam valores num√©ricos (ex.: `Age`, `Outstanding_Debt`, `Amount_invested_monthly`) ser√£o convertidas para `float64` usando `pd.to_numeric(errors='coerce')`.  \n",
    "- Valores que n√£o puderem ser convertidos se tornar√£o `NaN` de forma rastre√°vel.\n",
    "\n",
    "### üîπ Tratamento de Anomalias Num√©ricas\n",
    "- Idades negativas ou entradas n√£o num√©ricas (ex.: `-500`, `28_`) ser√£o convertidas em `NaN` e imputadas com a mediana da coluna `Age`.\n",
    "- Valores absurdos ou placeholders (ex.: `__10000__`) ter√£o caracteres especiais removidos e ser√£o convertidos para n√∫mero se poss√≠vel.\n",
    "\n",
    "### üîπ Valores Ausentes\n",
    "- Vari√°veis num√©ricas cont√≠nuas com nulos (ex.: `Monthly_Inhand_Salary`, `Credit_History_Age`) ser√£o imputadas com a mediana, pois s√£o menos sens√≠veis a outliers.\n",
    "- Vari√°veis categ√≥ricas com nulos (ex.: `Occupation`, `Payment_Behaviour`) receber√£o a categoria `Unknown` para manter integridade sem supor informa√ß√£o.\n",
    "\n",
    "### üîπ Outliers\n",
    "- Para colunas financeiras como `Annual_Income` e `Outstanding_Debt`, aplicaremos Winsorization limitando os extremos aos percentis 1% e 99% para reduzir impacto de valores distorcidos.\n",
    "\n",
    "### üîπ Padroniza√ß√£o de Strings\n",
    "- Placeholder como `_______` e ru√≠dos do tipo `!@9#%8` ser√£o substitu√≠dos por `Unknown`.\n",
    "- Campos com `Yes/No` ser√£o convertidos para padr√£o bin√°rio se necess√°rio na fase de modelagem.\n",
    "\n",
    "### üîπ Split e Persist√™ncia\n",
    "- Ap√≥s o tratamento, o dataset limpo ser√° salvo em `data/processed/` versionado com DVC, pronto para rastreio no MLflow.\n",
    "- Esta etapa encerra o pr√©-processamento, mantendo coer√™ncia para o treino e serving via API posteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3689d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos originais:\n",
      "Age                        object\n",
      "Annual_Income              object\n",
      "Outstanding_Debt           object\n",
      "Amount_invested_monthly    object\n",
      "Monthly_Balance            object\n",
      "dtype: object\n",
      "\n",
      "Tipos ap√≥s coer√ß√£o:\n",
      "Age                        float64\n",
      "Annual_Income              float64\n",
      "Outstanding_Debt           float64\n",
      "Amount_invested_monthly    float64\n",
      "Monthly_Balance            float64\n",
      "dtype: object\n",
      "\n",
      "Valores NaN adicionados por coer√ß√£o:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CONVERS√ÉO DE TIPOS NUM√âRICOS COM COER√á√ÉO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de colunas identificadas como num√©ricas, mas com tipo object\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: tipos originais\n",
    "print(\"Tipos originais:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Aplica coer√ß√£o para float64\n",
    "for col in numeric_cols:\n",
    "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "\n",
    "# Depois: tipos convertidos\n",
    "print(\"\\nTipos ap√≥s coer√ß√£o:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Verifica quantos valores viraram NaN\n",
    "print(\"\\nValores NaN adicionados por coer√ß√£o:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cf435",
   "metadata": {},
   "source": [
    "## Imputa√ß√£o de Valores Ausentes ‚Äî Colunas Num√©ricas\n",
    "\n",
    "Ap√≥s converter colunas num√©ricas para tipos coerentes, aplicamos imputa√ß√£o de `NaN` usando **mediana** para vari√°veis cont√≠nuas.  \n",
    "Esta abordagem √© robusta contra distor√ß√µes de valores extremos, mant√©m o vi√©s controlado e respeita o hist√≥rico real do dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN antes da imputa√ß√£o:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n",
      "Imputado Age com mediana = 33.0\n",
      "Imputado Annual_Income com mediana = 37550.74\n",
      "Imputado Outstanding_Debt com mediana = 1166.37\n",
      "Imputado Amount_invested_monthly com mediana = 128.95453805190283\n",
      "Imputado Monthly_Balance com mediana = 336.73122455696387\n",
      "\n",
      "NaN ap√≥s imputa√ß√£o:\n",
      "Age                        0\n",
      "Annual_Income              0\n",
      "Outstanding_Debt           0\n",
      "Amount_invested_monthly    0\n",
      "Monthly_Balance            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: IMPUTAR VALORES AUSENTES COM MEDIANA\n",
    "\n",
    "# Define novamente as colunas num√©ricas que j√° foram convertidas\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: mostra quantos NaN existem\n",
    "print(\"NaN antes da imputa√ß√£o:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n",
    "\n",
    "# Aplica imputa√ß√£o da mediana, coluna por coluna\n",
    "for col in numeric_cols:\n",
    "    median_value = df_train[col].median()\n",
    "    df_train[col] = df_train[col].fillna(median_value)\n",
    "    print(f\"Imputado {col} com mediana = {median_value}\")\n",
    "\n",
    "# Depois: verifica se ainda restaram NaN\n",
    "print(\"\\nNaN ap√≥s imputa√ß√£o:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8867",
   "metadata": {},
   "source": [
    "## Limpeza de Placeholders e Ru√≠dos ‚Äî Colunas Categ√≥ricas\n",
    "\n",
    "Ap√≥s a imputa√ß√£o num√©rica, iniciamos a padroniza√ß√£o de colunas categ√≥ricas que apresentam valores placeholders ou s√≠mbolos de ru√≠do.  \n",
    "Entradas como `_______`, `______`, `__`, `!@9#%8` e varia√ß√µes similares ser√£o substitu√≠das por `Unknown` para garantir consist√™ncia e coer√™ncia nos modelos.  \n",
    "Esta abordagem segue o princ√≠pio de **n√£o supor valores** quando n√£o h√° base para infer√™ncia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2da97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coluna: Occupation\n",
      "Antes: ['Scientist' '_______' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "Depois: ['Scientist' 'Unknown' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "\n",
      "Coluna: Payment_Behaviour\n",
      "Antes: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' '!@9#%8'\n",
      " 'High_spent_Large_value_payments']\n",
      "Depois: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' 'Unknown'\n",
      " 'High_spent_Large_value_payments']\n",
      "\n",
      "Coluna: Credit_Mix\n",
      "Antes: ['_' 'Good' 'Standard' 'Bad']\n",
      "Depois: ['Unknown' 'Good' 'Standard' 'Bad']\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: LIMPEZA DE PLACEHOLDERS E RU√çDOS EM CATEG√ìRICAS\n",
    "\n",
    "# Lista de colunas categ√≥ricas sens√≠veis a ru√≠do (ajuste conforme necess√°rio)\n",
    "categorical_cols = [\n",
    "    \"Occupation\",\n",
    "    \"Payment_Behaviour\",\n",
    "    \"Credit_Mix\"\n",
    "]\n",
    "\n",
    "# Padr√µes que vamos considerar como ru√≠do ou placeholder\n",
    "placeholder_patterns = [\"_______\", \"______\", \"__\", \"!@9#%8\", \"_\", \"__10000__\"]\n",
    "\n",
    "# Substitui por 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    original_unique = df_train[col].unique()\n",
    "    df_train[col] = df_train[col].replace(placeholder_patterns, \"Unknown\")\n",
    "    updated_unique = df_train[col].unique()\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Antes: {original_unique}\")\n",
    "    print(f\"Depois: {updated_unique}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850173a4",
   "metadata": {},
   "source": [
    "## Persist√™ncia do Dataset Limpo em `data/processed/`\n",
    "\n",
    "Ap√≥s convers√£o de tipos, imputa√ß√£o de valores ausentes e padroniza√ß√£o de placeholders, o dataset est√° pronto para ser salvo em `data/processed/`.  \n",
    "A pasta segue a estrutura **cookiecutter-data-science**, separando dados brutos (`raw/`) de dados prontos para modelagem (`processed/`).  \n",
    "O artefato ser√° versionado com DVC para garantir rastreabilidade integral at√© o MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19058f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvo em: ../data/processed/train_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: SALVAR DATASET TRATADO EM data/processed/\n",
    "\n",
    "import os\n",
    "\n",
    "# Define caminho coerente\n",
    "processed_dir = \"../data/processed\"  # se seu notebook roda em /notebooks\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Nome do arquivo tratado\n",
    "output_path = os.path.join(processed_dir, \"train_clean.csv\")\n",
    "\n",
    "# Salva CSV limpo\n",
    "df_train.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset salvo em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44381e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m‚†ã\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in ../data/processed/train_clean.csv |0.00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding ../data/processed/train_clean.c0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /workspace/data/processed0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|1/1 [00:00, 12.04file/s]\u001b[A\n",
      "Collecting                                            |4.00 [00:00,  295entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Querying remote cache|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|1/1 [00:00<00:00,  4.31files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/0 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mba-mlops-bucket/files/md5'| |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to s3                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/workspace/.dvc/cache/files/md50.00/30.1M [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|/workspace/.dvc/cache/file30.1M/30.1M [00:00<00:00,     256MB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|Pushing to s3                     1/1 [00:00<00:00,  7.60file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0mfatal: pathspec 'dvc.yaml' did not match any files\n",
      "[main 6ad2e6e] Vers√£o limpa do dataset treino persistida e versionada com DVC\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/processed/train_clean.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc add ../data/processed/train_clean.csv\n",
    "!dvc push\n",
    "!git add ../data/processed/train_clean.csv.dvc dvc.yaml\n",
    "!git commit -m \"Vers√£o limpa do dataset treino persistida e versionada com DVC\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
