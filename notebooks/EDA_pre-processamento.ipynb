{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1c384c",
   "metadata": {},
   "source": [
    "## Fase 5 ‚Äî EDA e Pr√©-processamento\n",
    "\n",
    "Nesta fase iniciaremos o **Item 5 do Plano de Atividades**, respons√°vel por abrir a etapa de **An√°lise Explorat√≥ria de Dados (EDA)** do conjunto real de dados versionado.  \n",
    "O objetivo √© garantir que os arquivos `train.csv` e `test.csv` estejam corretamente estruturados, analisar tipos de vari√°veis, valores ausentes, estat√≠sticas b√°sicas e poss√≠veis inconsist√™ncias.  \n",
    "Todo o trabalho ser√° executado dentro do **DevContainer**, com **rastreabilidade total**, utilizando sempre caminhos relativos revisados fisicamente, em conformidade com o **PROTOCOLO V5.4**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97ed987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD Kernel: /workspace/notebooks\n",
      "Conte√∫do de data/raw/: ['test.csv', 'train.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_310944/465301536.py:17: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato treino: (100000, 28)\n",
      "Formato teste: (50000, 27)\n",
      "\n",
      "Tipos de colunas treino:\n",
      "ID                           object\n",
      "Customer_ID                  object\n",
      "Month                        object\n",
      "Name                         object\n",
      "Age                          object\n",
      "SSN                          object\n",
      "Occupation                   object\n",
      "Annual_Income                object\n",
      "Monthly_Inhand_Salary       float64\n",
      "Num_Bank_Accounts             int64\n",
      "Num_Credit_Card               int64\n",
      "Interest_Rate                 int64\n",
      "Num_of_Loan                  object\n",
      "Type_of_Loan                 object\n",
      "Delay_from_due_date           int64\n",
      "Num_of_Delayed_Payment       object\n",
      "Changed_Credit_Limit         object\n",
      "Num_Credit_Inquiries        float64\n",
      "Credit_Mix                   object\n",
      "Outstanding_Debt             object\n",
      "Credit_Utilization_Ratio    float64\n",
      "Credit_History_Age           object\n",
      "Payment_of_Min_Amount        object\n",
      "Total_EMI_per_month         float64\n",
      "Amount_invested_monthly      object\n",
      "Payment_Behaviour            object\n",
      "Monthly_Balance              object\n",
      "Credit_Score                 object\n",
      "dtype: object\n",
      "\n",
      "Valores nulos treino:\n",
      "ID                              0\n",
      "Customer_ID                     0\n",
      "Month                           0\n",
      "Name                         9985\n",
      "Age                             0\n",
      "SSN                             0\n",
      "Occupation                      0\n",
      "Annual_Income                   0\n",
      "Monthly_Inhand_Salary       15002\n",
      "Num_Bank_Accounts               0\n",
      "Num_Credit_Card                 0\n",
      "Interest_Rate                   0\n",
      "Num_of_Loan                     0\n",
      "Type_of_Loan                11408\n",
      "Delay_from_due_date             0\n",
      "Num_of_Delayed_Payment       7002\n",
      "Changed_Credit_Limit            0\n",
      "Num_Credit_Inquiries         1965\n",
      "Credit_Mix                      0\n",
      "Outstanding_Debt                0\n",
      "Credit_Utilization_Ratio        0\n",
      "Credit_History_Age           9030\n",
      "Payment_of_Min_Amount           0\n",
      "Total_EMI_per_month             0\n",
      "Amount_invested_monthly      4479\n",
      "Payment_Behaviour               0\n",
      "Monthly_Balance              1200\n",
      "Credit_Score                    0\n",
      "dtype: int64\n",
      "\n",
      "Amostra treino:\n",
      "        ID Customer_ID     Month             Name   Age          SSN  \\\n",
      "0   0x1602   CUS_0xd40   January    Aaron Maashoh    23  821-00-0265   \n",
      "1   0x1603   CUS_0xd40  February    Aaron Maashoh    23  821-00-0265   \n",
      "2   0x1604   CUS_0xd40     March    Aaron Maashoh  -500  821-00-0265   \n",
      "3   0x1605   CUS_0xd40     April    Aaron Maashoh    23  821-00-0265   \n",
      "4   0x1606   CUS_0xd40       May    Aaron Maashoh    23  821-00-0265   \n",
      "5   0x1607   CUS_0xd40      June    Aaron Maashoh    23  821-00-0265   \n",
      "6   0x1608   CUS_0xd40      July    Aaron Maashoh    23  821-00-0265   \n",
      "7   0x1609   CUS_0xd40    August              NaN    23    #F%$D@*&8   \n",
      "8   0x160e  CUS_0x21b1   January  Rick Rothackerj   28_  004-07-5839   \n",
      "9   0x160f  CUS_0x21b1  February  Rick Rothackerj    28  004-07-5839   \n",
      "10  0x1610  CUS_0x21b1     March  Rick Rothackerj    28  004-07-5839   \n",
      "11  0x1611  CUS_0x21b1     April  Rick Rothackerj    28  004-07-5839   \n",
      "12  0x1612  CUS_0x21b1       May  Rick Rothackerj    28  004-07-5839   \n",
      "13  0x1613  CUS_0x21b1      June  Rick Rothackerj    28  004-07-5839   \n",
      "14  0x1614  CUS_0x21b1      July  Rick Rothackerj    28  004-07-5839   \n",
      "15  0x1615  CUS_0x21b1    August  Rick Rothackerj    28  004-07-5839   \n",
      "16  0x161a  CUS_0x2dbc   January           Langep    34  486-85-3974   \n",
      "17  0x161b  CUS_0x2dbc  February              NaN    34  486-85-3974   \n",
      "18  0x161c  CUS_0x2dbc     March           Langep    34  486-85-3974   \n",
      "19  0x161d  CUS_0x2dbc     April           Langep    34  486-85-3974   \n",
      "\n",
      "   Occupation Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
      "0   Scientist      19114.12            1824.843333                  3  ...   \n",
      "1   Scientist      19114.12                    NaN                  3  ...   \n",
      "2   Scientist      19114.12                    NaN                  3  ...   \n",
      "3   Scientist      19114.12                    NaN                  3  ...   \n",
      "4   Scientist      19114.12            1824.843333                  3  ...   \n",
      "5   Scientist      19114.12                    NaN                  3  ...   \n",
      "6   Scientist      19114.12            1824.843333                  3  ...   \n",
      "7   Scientist      19114.12            1824.843333                  3  ...   \n",
      "8     _______      34847.84            3037.986667                  2  ...   \n",
      "9     Teacher      34847.84            3037.986667                  2  ...   \n",
      "10    Teacher     34847.84_            3037.986667                  2  ...   \n",
      "11    Teacher      34847.84                    NaN                  2  ...   \n",
      "12    Teacher      34847.84            3037.986667                  2  ...   \n",
      "13    Teacher      34847.84            3037.986667                  2  ...   \n",
      "14    Teacher      34847.84                    NaN                  2  ...   \n",
      "15    Teacher      34847.84            3037.986667                  2  ...   \n",
      "16    _______     143162.64           12187.220000                  1  ...   \n",
      "17   Engineer     143162.64           12187.220000                  1  ...   \n",
      "18    _______     143162.64                    NaN                  1  ...   \n",
      "19   Engineer     143162.64           12187.220000                  1  ...   \n",
      "\n",
      "    Credit_Mix  Outstanding_Debt Credit_Utilization_Ratio  \\\n",
      "0            _            809.98                26.822620   \n",
      "1         Good            809.98                31.944960   \n",
      "2         Good            809.98                28.609352   \n",
      "3         Good            809.98                31.377862   \n",
      "4         Good            809.98                24.797347   \n",
      "5         Good            809.98                27.262259   \n",
      "6         Good            809.98                22.537593   \n",
      "7         Good            809.98                23.933795   \n",
      "8         Good            605.03                24.464031   \n",
      "9         Good            605.03                38.550848   \n",
      "10           _            605.03                33.224951   \n",
      "11        Good            605.03                39.182656   \n",
      "12        Good            605.03                34.977895   \n",
      "13        Good            605.03                33.381010   \n",
      "14        Good            605.03                31.131702   \n",
      "15        Good            605.03                32.933856   \n",
      "16        Good           1303.01                28.616735   \n",
      "17        Good           1303.01                41.702573   \n",
      "18        Good           1303.01                26.519815   \n",
      "19           _           1303.01                39.501648   \n",
      "\n",
      "        Credit_History_Age  Payment_of_Min_Amount Total_EMI_per_month  \\\n",
      "0    22 Years and 1 Months                     No           49.574949   \n",
      "1                      NaN                     No           49.574949   \n",
      "2    22 Years and 3 Months                     No           49.574949   \n",
      "3    22 Years and 4 Months                     No           49.574949   \n",
      "4    22 Years and 5 Months                     No           49.574949   \n",
      "5    22 Years and 6 Months                     No           49.574949   \n",
      "6    22 Years and 7 Months                     No           49.574949   \n",
      "7                      NaN                     No           49.574949   \n",
      "8    26 Years and 7 Months                     No           18.816215   \n",
      "9    26 Years and 8 Months                     No           18.816215   \n",
      "10   26 Years and 9 Months                     No           18.816215   \n",
      "11  26 Years and 10 Months                     No           18.816215   \n",
      "12  26 Years and 11 Months                     No           18.816215   \n",
      "13   27 Years and 0 Months                     No           18.816215   \n",
      "14   27 Years and 1 Months                     NM           18.816215   \n",
      "15   27 Years and 2 Months                     No           18.816215   \n",
      "16   17 Years and 9 Months                     No          246.992319   \n",
      "17  17 Years and 10 Months                     No          246.992319   \n",
      "18  17 Years and 11 Months                     No          246.992319   \n",
      "19                     NaN                     No          246.992319   \n",
      "\n",
      "   Amount_invested_monthly                 Payment_Behaviour  \\\n",
      "0        80.41529543900253   High_spent_Small_value_payments   \n",
      "1       118.28022162236736    Low_spent_Large_value_payments   \n",
      "2          81.699521264648   Low_spent_Medium_value_payments   \n",
      "3        199.4580743910713    Low_spent_Small_value_payments   \n",
      "4       41.420153086217326  High_spent_Medium_value_payments   \n",
      "5       62.430172331195294                            !@9#%8   \n",
      "6        178.3440674122349    Low_spent_Small_value_payments   \n",
      "7       24.785216509052056  High_spent_Medium_value_payments   \n",
      "8         104.291825168246    Low_spent_Small_value_payments   \n",
      "9        40.39123782853101   High_spent_Large_value_payments   \n",
      "10       58.51597569589465   High_spent_Large_value_payments   \n",
      "11       99.30622796053305   Low_spent_Medium_value_payments   \n",
      "12      130.11542024292334    Low_spent_Small_value_payments   \n",
      "13      43.477190144355745   High_spent_Large_value_payments   \n",
      "14       70.10177420755677  High_spent_Medium_value_payments   \n",
      "15      218.90434353388733    Low_spent_Small_value_payments   \n",
      "16        168.413702679309                            !@9#%8   \n",
      "17      232.86038375993544   High_spent_Small_value_payments   \n",
      "18               __10000__   High_spent_Small_value_payments   \n",
      "19       825.2162699393922   Low_spent_Medium_value_payments   \n",
      "\n",
      "       Monthly_Balance Credit_Score  \n",
      "0   312.49408867943663         Good  \n",
      "1   284.62916249607184         Good  \n",
      "2    331.2098628537912         Good  \n",
      "3   223.45130972736786         Good  \n",
      "4   341.48923103222177         Good  \n",
      "5    340.4792117872438         Good  \n",
      "6    244.5653167062043         Good  \n",
      "7   358.12416760938714     Standard  \n",
      "8   470.69062692529184     Standard  \n",
      "9    484.5912142650067         Good  \n",
      "10  466.46647639764313     Standard  \n",
      "11   465.6762241330048         Good  \n",
      "12   444.8670318506144         Good  \n",
      "13    481.505261949182         Good  \n",
      "14   464.8806778859809         Good  \n",
      "15  356.07810855965045         Good  \n",
      "16  1043.3159778669492         Good  \n",
      "17   998.8692967863226         Good  \n",
      "18    715.741367403555         Good  \n",
      "19   426.5134106068658         Good  \n",
      "\n",
      "[20 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CARREGAR E INSPECIONAR O DATASET REAL\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Confirma diret√≥rio de trabalho do Kernel\n",
    "print(\"CWD Kernel:\", os.getcwd())\n",
    "\n",
    "# Define caminho coerente para o dataset real\n",
    "# Se o notebook estiver dentro de notebooks/, usar ../data/raw/\n",
    "data_raw_dir = \"../data/raw\"\n",
    "\n",
    "# Lista arquivos para validar nomes reais\n",
    "print(\"Conte√∫do de data/raw/:\", os.listdir(data_raw_dir))\n",
    "\n",
    "# Carrega arquivos reais versionados\n",
    "df_train = pd.read_csv(os.path.join(data_raw_dir, \"train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(data_raw_dir, \"test.csv\"))\n",
    "\n",
    "# Verifica estrutura inicial\n",
    "print(\"Formato treino:\", df_train.shape)\n",
    "print(\"Formato teste:\", df_test.shape)\n",
    "\n",
    "print(\"\\nTipos de colunas treino:\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "print(\"\\nValores nulos treino:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nAmostra treino:\")\n",
    "print(df_train.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50236b0c",
   "metadata": {},
   "source": [
    "## An√°lise da C√©lula de Carregamento e Inspe√ß√£o Inicial\n",
    "\n",
    "A leitura dos arquivos `train.csv` e `test.csv` confirma que o dataset real est√° estruturado e coerente com o versionamento em `data/raw/`.  \n",
    "O `train.csv` possui **100.000 linhas √ó 28 colunas** e o `test.csv` **50.000 linhas √ó 27 colunas**. A listagem do diret√≥rio validou os nomes dos arquivos sem depend√™ncia de heur√≠stica, alinhado ao **PROTOCOLO V5.4**.\n",
    "\n",
    "### Principais observa√ß√µes:\n",
    "\n",
    "- **DtypeWarning:** A leitura acusou tipos mistos em algumas colunas (ex.: coluna 26), indicando registros com strings, s√≠mbolos ou formatos inconsistentes em campos que deveriam ser num√©ricos.\n",
    "- **Tipos de colunas:** Diversas vari√°veis num√©ricas (`Age`, `Outstanding_Debt`, `Amount_invested_monthly` etc.) foram lidas como `object`. Isso confirma a necessidade de convers√£o expl√≠cita para tipos num√©ricos (`int64` ou `float64`) usando coer√ß√£o.\n",
    "- **Valores ausentes:** A contagem de `NaN` revelou lacunas relevantes em campos como `Name` (~10%), `Monthly_Inhand_Salary` (~15%), `Credit_History_Age` (~9%) e `Num_of_Delayed_Payment`. Ser√° necess√°rio definir pol√≠ticas de imputa√ß√£o ou descarte.\n",
    "- **Amostra de registros:** Identificou anomalias claras, como `Age` negativo ou inv√°lido (`-500`, `28_`), ocupa√ß√µes `_______` e padr√µes de ru√≠do como `!@9#%8` em `Payment_Behaviour`. Estes valores precisar√£o ser tratados na fase de limpeza.\n",
    "\n",
    "Esta an√°lise serve como base para planejar o pr√©-processamento, garantindo integridade e consist√™ncia antes de avan√ßar para treinamento e rastreio de experimentos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa35f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Pol√≠ticas de Tratamento de Dados ‚Äî Defini√ß√£o Oficial\n",
    "\n",
    "Com base na an√°lise explorat√≥ria inicial e nos requisitos do exerc√≠cio, definimos as seguintes diretrizes de limpeza e padroniza√ß√£o para o dataset `credit-score-classification`. Todas as etapas respeitam o **PROTOCOLO V5.4** e garantem rastreabilidade do pipeline.\n",
    "\n",
    "### üîπ Convers√£o de Tipos\n",
    "- Todas as colunas identificadas como `object` mas que representam valores num√©ricos (ex.: `Age`, `Outstanding_Debt`, `Amount_invested_monthly`) ser√£o convertidas para `float64` usando `pd.to_numeric(errors='coerce')`.  \n",
    "- Valores que n√£o puderem ser convertidos se tornar√£o `NaN` de forma rastre√°vel.\n",
    "\n",
    "### üîπ Tratamento de Anomalias Num√©ricas\n",
    "- Idades negativas ou entradas n√£o num√©ricas (ex.: `-500`, `28_`) ser√£o convertidas em `NaN` e imputadas com a mediana da coluna `Age`.\n",
    "- Valores absurdos ou placeholders (ex.: `__10000__`) ter√£o caracteres especiais removidos e ser√£o convertidos para n√∫mero se poss√≠vel.\n",
    "\n",
    "### üîπ Valores Ausentes\n",
    "- Vari√°veis num√©ricas cont√≠nuas com nulos (ex.: `Monthly_Inhand_Salary`, `Credit_History_Age`) ser√£o imputadas com a mediana, pois s√£o menos sens√≠veis a outliers.\n",
    "- Vari√°veis categ√≥ricas com nulos (ex.: `Occupation`, `Payment_Behaviour`) receber√£o a categoria `Unknown` para manter integridade sem supor informa√ß√£o.\n",
    "\n",
    "### üîπ Outliers\n",
    "- Para colunas financeiras como `Annual_Income` e `Outstanding_Debt`, aplicaremos Winsorization limitando os extremos aos percentis 1% e 99% para reduzir impacto de valores distorcidos.\n",
    "\n",
    "### üîπ Padroniza√ß√£o de Strings\n",
    "- Placeholder como `_______` e ru√≠dos do tipo `!@9#%8` ser√£o substitu√≠dos por `Unknown`.\n",
    "- Campos com `Yes/No` ser√£o convertidos para padr√£o bin√°rio se necess√°rio na fase de modelagem.\n",
    "\n",
    "### üîπ Split e Persist√™ncia\n",
    "- Ap√≥s o tratamento, o dataset limpo ser√° salvo em `data/processed/` versionado com DVC, pronto para rastreio no MLflow.\n",
    "- Esta etapa encerra o pr√©-processamento, mantendo coer√™ncia para o treino e serving via API posteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3689d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos originais:\n",
      "Age                        object\n",
      "Annual_Income              object\n",
      "Outstanding_Debt           object\n",
      "Amount_invested_monthly    object\n",
      "Monthly_Balance            object\n",
      "dtype: object\n",
      "\n",
      "Tipos ap√≥s coer√ß√£o:\n",
      "Age                        float64\n",
      "Annual_Income              float64\n",
      "Outstanding_Debt           float64\n",
      "Amount_invested_monthly    float64\n",
      "Monthly_Balance            float64\n",
      "dtype: object\n",
      "\n",
      "Valores NaN adicionados por coer√ß√£o:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: CONVERS√ÉO DE TIPOS NUM√âRICOS COM COER√á√ÉO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de colunas identificadas como num√©ricas, mas com tipo object\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: tipos originais\n",
    "print(\"Tipos originais:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Aplica coer√ß√£o para float64\n",
    "for col in numeric_cols:\n",
    "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "\n",
    "# Depois: tipos convertidos\n",
    "print(\"\\nTipos ap√≥s coer√ß√£o:\")\n",
    "print(df_train[numeric_cols].dtypes)\n",
    "\n",
    "# Verifica quantos valores viraram NaN\n",
    "print(\"\\nValores NaN adicionados por coer√ß√£o:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cf435",
   "metadata": {},
   "source": [
    "## Imputa√ß√£o de Valores Ausentes ‚Äî Colunas Num√©ricas\n",
    "\n",
    "Ap√≥s converter colunas num√©ricas para tipos coerentes, aplicamos imputa√ß√£o de `NaN` usando **mediana** para vari√°veis cont√≠nuas.  \n",
    "Esta abordagem √© robusta contra distor√ß√µes de valores extremos, mant√©m o vi√©s controlado e respeita o hist√≥rico real do dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN antes da imputa√ß√£o:\n",
      "Age                        4939\n",
      "Annual_Income              6980\n",
      "Outstanding_Debt           1009\n",
      "Amount_invested_monthly    8784\n",
      "Monthly_Balance            1209\n",
      "dtype: int64\n",
      "Imputado Age com mediana = 33.0\n",
      "Imputado Annual_Income com mediana = 37550.74\n",
      "Imputado Outstanding_Debt com mediana = 1166.37\n",
      "Imputado Amount_invested_monthly com mediana = 128.95453805190283\n",
      "Imputado Monthly_Balance com mediana = 336.73122455696387\n",
      "\n",
      "NaN ap√≥s imputa√ß√£o:\n",
      "Age                        0\n",
      "Annual_Income              0\n",
      "Outstanding_Debt           0\n",
      "Amount_invested_monthly    0\n",
      "Monthly_Balance            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: IMPUTAR VALORES AUSENTES COM MEDIANA\n",
    "\n",
    "# Define novamente as colunas num√©ricas que j√° foram convertidas\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Annual_Income\",\n",
    "    \"Outstanding_Debt\",\n",
    "    \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "\n",
    "# Antes: mostra quantos NaN existem\n",
    "print(\"NaN antes da imputa√ß√£o:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n",
    "\n",
    "# Aplica imputa√ß√£o da mediana, coluna por coluna\n",
    "for col in numeric_cols:\n",
    "    median_value = df_train[col].median()\n",
    "    df_train[col] = df_train[col].fillna(median_value)\n",
    "    print(f\"Imputado {col} com mediana = {median_value}\")\n",
    "\n",
    "# Depois: verifica se ainda restaram NaN\n",
    "print(\"\\nNaN ap√≥s imputa√ß√£o:\")\n",
    "print(df_train[numeric_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8867",
   "metadata": {},
   "source": [
    "## Limpeza de Placeholders e Ru√≠dos ‚Äî Colunas Categ√≥ricas\n",
    "\n",
    "Ap√≥s a imputa√ß√£o num√©rica, iniciamos a padroniza√ß√£o de colunas categ√≥ricas que apresentam valores placeholders ou s√≠mbolos de ru√≠do.  \n",
    "Entradas como `_______`, `______`, `__`, `!@9#%8` e varia√ß√µes similares ser√£o substitu√≠das por `Unknown` para garantir consist√™ncia e coer√™ncia nos modelos.  \n",
    "Esta abordagem segue o princ√≠pio de **n√£o supor valores** quando n√£o h√° base para infer√™ncia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2da97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coluna: Occupation\n",
      "Antes: ['Scientist' '_______' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "Depois: ['Scientist' 'Unknown' 'Teacher' 'Engineer' 'Entrepreneur' 'Developer'\n",
      " 'Lawyer' 'Media_Manager' 'Doctor' 'Journalist' 'Manager' 'Accountant'\n",
      " 'Musician' 'Mechanic' 'Writer' 'Architect']\n",
      "\n",
      "Coluna: Payment_Behaviour\n",
      "Antes: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' '!@9#%8'\n",
      " 'High_spent_Large_value_payments']\n",
      "Depois: ['High_spent_Small_value_payments' 'Low_spent_Large_value_payments'\n",
      " 'Low_spent_Medium_value_payments' 'Low_spent_Small_value_payments'\n",
      " 'High_spent_Medium_value_payments' 'Unknown'\n",
      " 'High_spent_Large_value_payments']\n",
      "\n",
      "Coluna: Credit_Mix\n",
      "Antes: ['_' 'Good' 'Standard' 'Bad']\n",
      "Depois: ['Unknown' 'Good' 'Standard' 'Bad']\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: LIMPEZA DE PLACEHOLDERS E RU√çDOS EM CATEG√ìRICAS\n",
    "\n",
    "# Lista de colunas categ√≥ricas sens√≠veis a ru√≠do (ajuste conforme necess√°rio)\n",
    "categorical_cols = [\n",
    "    \"Occupation\",\n",
    "    \"Payment_Behaviour\",\n",
    "    \"Credit_Mix\"\n",
    "]\n",
    "\n",
    "# Padr√µes que vamos considerar como ru√≠do ou placeholder\n",
    "placeholder_patterns = [\"_______\", \"______\", \"__\", \"!@9#%8\", \"_\", \"__10000__\"]\n",
    "\n",
    "# Substitui por 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    original_unique = df_train[col].unique()\n",
    "    df_train[col] = df_train[col].replace(placeholder_patterns, \"Unknown\")\n",
    "    updated_unique = df_train[col].unique()\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Antes: {original_unique}\")\n",
    "    print(f\"Depois: {updated_unique}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850173a4",
   "metadata": {},
   "source": [
    "## Persist√™ncia do Dataset Limpo em `data/processed/`\n",
    "\n",
    "Ap√≥s convers√£o de tipos, imputa√ß√£o de valores ausentes e padroniza√ß√£o de placeholders, o dataset est√° pronto para ser salvo em `data/processed/`.  \n",
    "A pasta segue a estrutura **cookiecutter-data-science**, separando dados brutos (`raw/`) de dados prontos para modelagem (`processed/`).  \n",
    "O artefato ser√° versionado com DVC para garantir rastreabilidade integral at√© o MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19058f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvo em: ../data/processed/train_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: SALVAR DATASET TRATADO EM data/processed/\n",
    "\n",
    "import os\n",
    "\n",
    "# Define caminho coerente\n",
    "processed_dir = \"../data/processed\"  # se seu notebook roda em /notebooks\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Nome do arquivo tratado\n",
    "output_path = os.path.join(processed_dir, \"train_clean.csv\")\n",
    "\n",
    "# Salva CSV limpo\n",
    "df_train.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset salvo em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44381e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m‚†ã\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in ../data/processed/train_clean.csv |0.00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding ../data/processed/train_clean.c0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /workspace/data/processed0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|1/1 [00:00, 12.04file/s]\u001b[A\n",
      "Collecting                                            |4.00 [00:00,  295entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Querying remote cache|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|1/1 [00:00<00:00,  4.31files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/0 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mba-mlops-bucket/files/md5'| |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to s3                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/workspace/.dvc/cache/files/md50.00/30.1M [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|/workspace/.dvc/cache/file30.1M/30.1M [00:00<00:00,     256MB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|Pushing to s3                     1/1 [00:00<00:00,  7.60file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0mfatal: pathspec 'dvc.yaml' did not match any files\n",
      "[main 6ad2e6e] Vers√£o limpa do dataset treino persistida e versionada com DVC\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/processed/train_clean.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc add ../data/processed/train_clean.csv\n",
    "!dvc push\n",
    "!git add ../data/processed/train_clean.csv.dvc dvc.yaml\n",
    "!git commit -m \"Vers√£o limpa do dataset treino persistida e versionada com DVC\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b198a",
   "metadata": {},
   "source": [
    "## Etapa Final ‚Äî Aplicar Pipeline de Pr√©-processamento no Conjunto de Teste\n",
    "\n",
    "Para manter consist√™ncia, aplicamos **exatamente o mesmo fluxo de tratamento usado no treino**:\n",
    "- Convers√£o de tipos num√©ricos com coer√ß√£o\n",
    "- Imputa√ß√£o de valores ausentes com mediana calculada no treino\n",
    "- Substitui√ß√£o de placeholders e ru√≠dos por `Unknown`\n",
    "- Codifica√ß√£o categ√≥rica usando o mesmo esquema de colunas do treino\n",
    "\n",
    "Isso garante que `X_test` ter√° **as mesmas features** do `X_train` e poder√° ser usado sem risco de erro nos experimentos do MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ac9acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputado Age com mediana do treino = 33.0\n",
      "Imputado Annual_Income com mediana do treino = 37550.74\n",
      "Imputado Outstanding_Debt com mediana do treino = 1166.37\n",
      "Imputado Amount_invested_monthly com mediana do treino = 128.95453805190283\n",
      "Imputado Monthly_Balance com mediana do treino = 336.73122455696387\n",
      "Shape final df_test_clean: (50000, 46)\n",
      "Colunas finais: ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance', 'Month_November', 'Month_October', 'Month_September', 'Occupation_Architect', 'Occupation_Developer', 'Occupation_Doctor', 'Occupation_Engineer', 'Occupation_Entrepreneur', 'Occupation_Journalist', 'Occupation_Lawyer', 'Occupation_Manager', 'Occupation_Mechanic', 'Occupation_Media_Manager', 'Occupation_Musician', 'Occupation_Scientist', 'Occupation_Teacher', 'Occupation_Unknown', 'Occupation_Writer', 'Credit_Mix_Good', 'Credit_Mix_Standard', 'Credit_Mix_Unknown', 'Payment_Behaviour_High_spent_Medium_value_payments', 'Payment_Behaviour_High_spent_Small_value_payments', 'Payment_Behaviour_Low_spent_Large_value_payments', 'Payment_Behaviour_Low_spent_Medium_value_payments', 'Payment_Behaviour_Low_spent_Small_value_payments', 'Payment_Behaviour_Unknown']\n"
     ]
    }
   ],
   "source": [
    "# ETAPA FINAL: TRATAR CONJUNTO DE TESTE COM MESMA L√ìGICA DO TREINO\n",
    "\n",
    "# Copia test bruto\n",
    "df_test_clean = df_test.copy()\n",
    "\n",
    "# --- Convers√£o de tipos num√©ricos ---\n",
    "numeric_cols = [\"Age\", \"Annual_Income\", \"Outstanding_Debt\", \n",
    "                \"Amount_invested_monthly\", \"Monthly_Balance\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df_test_clean[col] = pd.to_numeric(df_test_clean[col], errors='coerce')\n",
    "\n",
    "# --- Imputa√ß√£o de valores ausentes com mediana calculada no treino ---\n",
    "for col in numeric_cols:\n",
    "    median_value = df_train[col].median()\n",
    "    df_test_clean[col] = df_test_clean[col].fillna(median_value)\n",
    "    print(f\"Imputado {col} com mediana do treino = {median_value}\")\n",
    "\n",
    "# --- Limpeza de placeholders/ru√≠dos ---\n",
    "categorical_cols = [\"Occupation\", \"Payment_Behaviour\", \"Credit_Mix\"]\n",
    "placeholder_patterns = [\"_______\", \"______\", \"__\", \"!@9#%8\", \"_\", \"__10000__\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_test_clean[col] = df_test_clean[col].replace(placeholder_patterns, \"Unknown\")\n",
    "\n",
    "# --- Drop de colunas ID-only ---\n",
    "cols_to_drop = [\"ID\", \"Customer_ID\", \"Name\", \"SSN\"]\n",
    "df_test_clean = df_test_clean.drop(columns=cols_to_drop)\n",
    "\n",
    "# --- Codifica√ß√£o one-hot coerente ---\n",
    "df_test_clean = pd.get_dummies(df_test_clean, columns=[\"Month\", \"Occupation\", \n",
    "                                                       \"Credit_Mix\", \"Payment_Behaviour\"],\n",
    "                               drop_first=True)\n",
    "\n",
    "print(\"Shape final df_test_clean:\", df_test_clean.shape)\n",
    "print(\"Colunas finais:\", df_test_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faca7f1",
   "metadata": {},
   "source": [
    "##  Persist√™ncia do Conjunto de Teste no `processed`\n",
    "\n",
    "Ap√≥s aplicar todo o pipeline de pr√©-processamento coerente com o treino, o conjunto de teste ser√° salvo em `data/processed/`.  \n",
    "Este arquivo garante que o `X_test` final ter√° as mesmas transforma√ß√µes do `X_train`, ficando pronto para experimentos no MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e39f9311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: /workspace/data/processed/test_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA FINAL: SALVAR TESTE TRATADO EM /workspace/data/processed/\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# For√ßa caminho base coerente (mesmo que rode em /workspace/notebooks)\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    processed_dir = cwd.parent / \"data\" / \"processed\"\n",
    "else:\n",
    "    processed_dir = cwd / \"data\" / \"processed\"\n",
    "\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Caminho final padronizado: test_clean.csv\n",
    "test_clean_path = processed_dir / \"test_clean.csv\"\n",
    "\n",
    "# Salva CSV limpo\n",
    "df_test_clean.to_csv(test_clean_path, index=False)\n",
    "\n",
    "print(f\"Arquivo salvo em: {test_clean_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8287c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD Kernel: /workspace/notebooks\n",
      "Caminho usado no dvc add: ../data/processed/test_clean.csv\n",
      " \u001b[?25l\u001b[32m‚†ã\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in ../data/processed/test_clean.csv |0.00 \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding ../data/processed/test_clean.cs0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /workspace/data/processed0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|1/1 [00:00, 19.59file/s]\u001b[A\n",
      "Collecting                                            |5.00 [00:00,  321entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Querying remote cache|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|1/1 [00:00<00:00,  4.11files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/0 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mba-mlops-bucket/files/md5'| |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/workspace/.dvc/cache/files/md5'| |0/? [00:00<?,    ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to s3                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/workspace/.dvc/cache/files/md50.00/17.9M [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0m[main 2750532] Adiciona test_clean.csv versionado na camada processed\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/processed/test_clean.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "# ETAPA √öNICA: CONFERE CWD, AJUSTA CAMINHO E VERSIONA test_clean.csv CORRETAMENTE\n",
    "\n",
    "import os\n",
    "\n",
    "# 1) Confirma onde o Kernel est√° rodando\n",
    "cwd = os.getcwd()\n",
    "print(f\"CWD Kernel: {cwd}\")\n",
    "\n",
    "# 2) Define caminho relativo coerente\n",
    "if cwd.endswith(\"notebooks\"):\n",
    "    path_to_file = \"../data/processed/test_clean.csv\"\n",
    "    path_to_dvc = \"../data/processed/test_clean.csv.dvc\"\n",
    "else:\n",
    "    path_to_file = \"data/processed/test_clean.csv\"\n",
    "    path_to_dvc = \"data/processed/test_clean.csv.dvc\"\n",
    "\n",
    "print(f\"Caminho usado no dvc add: {path_to_file}\")\n",
    "\n",
    "# 3) Executa shell no Jupyter usando !\n",
    "!dvc add {path_to_file}\n",
    "!dvc push\n",
    "!git add {path_to_dvc}\n",
    "!git commit -m \"Adiciona test_clean.csv versionado na camada processed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb31c2",
   "metadata": {},
   "source": [
    "---\n",
    "REFATORAMENTO DO CLEAN.CSV\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed88e9",
   "metadata": {},
   "source": [
    "## ETAPA: PADR√ÉO DE CURADORIA ‚Äî RAW ‚ûú CLEAN V1\n",
    "\n",
    "Aplicamos o mesmo pipeline de curadoria para `RAW TRAIN` e `RAW TEST`:\n",
    "\n",
    "1Ô∏è‚É£ Remo√ß√£o de colunas identificadoras: `ID`, `Customer_ID`, `Name`, `SSN`.  \n",
    "2Ô∏è‚É£ Substitui√ß√£o de placeholders: `'Unknown'`, `'_______'`, `'!@9#%8'`, `'#F%$D@*&8'` ‚ûú `Other`.  \n",
    "3Ô∏è‚É£ Coer√ß√£o de tipos para colunas num√©ricas (`Age`, `Annual_Income`, `Monthly_Inhand_Salary`, `Changed_Credit_Limit`, `Outstanding_Debt` etc.).  \n",
    "4Ô∏è‚É£ Corre√ß√£o de outliers l√≥gicos (ex: `Age` < 0 ‚ûú `NaN`, `Num_Bank_Accounts` = -1 ‚ûú 0).  \n",
    "5Ô∏è‚É£ Imputa√ß√£o de `NaN` para num√©ricas usando **mediana agrupada por `Occupation`**, com fallback para mediana global.\n",
    "6Ô∏è‚É£ Imputa√ß√£o de `Occupation` ausente com moda.\n",
    "7Ô∏è‚É£ Nenhuma codifica√ß√£o `get_dummies` neste est√°gio ‚Äî `Occupation` permanece nominal.\n",
    "8Ô∏è‚É£ Salvo como `train_clean_v1.csv` e `test_clean_v1.csv`.\n",
    "9Ô∏è‚É£ Versionamento DVC para rastreabilidade.\n",
    "\n",
    "Todo o fluxo rastreado no **PROTOCOLO V5.4**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbaccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77546/3315925519.py:10: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(TRAIN_RAW_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAW TRAIN shape: (100000, 28)\n",
      "‚úÖ RAW TEST shape: (50000, 27)\n",
      "‚úÖ TRAIN CLEAN V1: (100000, 24)\n",
      "‚úÖ TEST CLEAN V1: (50000, 23)\n",
      "\n",
      "üîç Preview TRAIN CLEAN V1:\n",
      "      Month   Age Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
      "0   January  23.0  Scientist       19114.12            1824.843333   \n",
      "1  February  23.0  Scientist       19114.12            3260.465000   \n",
      "2     March  33.0  Scientist       19114.12            3260.465000   \n",
      "3     April  23.0  Scientist       19114.12            3260.465000   \n",
      "4       May  23.0  Scientist       19114.12            1824.843333   \n",
      "\n",
      "   Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
      "0                  3                4              3          4.0   \n",
      "1                  3                4              3          4.0   \n",
      "2                  3                4              3          4.0   \n",
      "3                  3                4              3          4.0   \n",
      "4                  3                4              3          4.0   \n",
      "\n",
      "                                        Type_of_Loan  ...  Credit_Mix  \\\n",
      "0  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...           _   \n",
      "1  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "2  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "3  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "4  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...        Good   \n",
      "\n",
      "   Outstanding_Debt  Credit_Utilization_Ratio     Credit_History_Age  \\\n",
      "0            809.98                 26.822620  22 Years and 1 Months   \n",
      "1            809.98                 31.944960                    NaN   \n",
      "2            809.98                 28.609352  22 Years and 3 Months   \n",
      "3            809.98                 31.377862  22 Years and 4 Months   \n",
      "4            809.98                 24.797347  22 Years and 5 Months   \n",
      "\n",
      "  Payment_of_Min_Amount  Total_EMI_per_month  Amount_invested_monthly  \\\n",
      "0                    No            49.574949        80.41529543900253   \n",
      "1                    No            49.574949       118.28022162236736   \n",
      "2                    No            49.574949          81.699521264648   \n",
      "3                    No            49.574949        199.4580743910713   \n",
      "4                    No            49.574949       41.420153086217326   \n",
      "\n",
      "                  Payment_Behaviour     Monthly_Balance  Credit_Score  \n",
      "0   High_spent_Small_value_payments  312.49408867943663          Good  \n",
      "1    Low_spent_Large_value_payments  284.62916249607184          Good  \n",
      "2   Low_spent_Medium_value_payments   331.2098628537912          Good  \n",
      "3    Low_spent_Small_value_payments  223.45130972736786          Good  \n",
      "4  High_spent_Medium_value_payments  341.48923103222177          Good  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "üîç Preview TEST CLEAN V1:\n",
      "       Month   Age Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
      "0  September  23.0  Scientist       19114.12            1824.843333   \n",
      "1    October  24.0  Scientist       19114.12            1824.843333   \n",
      "2   November  24.0  Scientist       19114.12            1824.843333   \n",
      "3   December  34.0  Scientist       19114.12            3260.465000   \n",
      "4  September  28.0      Other       34847.84            3037.986667   \n",
      "\n",
      "   Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
      "0                  3                4              3          4.0   \n",
      "1                  3                4              3          4.0   \n",
      "2                  3                4              3          4.0   \n",
      "3                  3                4              3          4.0   \n",
      "4                  2                4              6          1.0   \n",
      "\n",
      "                                        Type_of_Loan  ...  \\\n",
      "0  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "1  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "2  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "3  Auto Loan, Credit-Builder Loan, Personal Loan,...  ...   \n",
      "4                                Credit-Builder Loan  ...   \n",
      "\n",
      "   Num_Credit_Inquiries  Credit_Mix  Outstanding_Debt  \\\n",
      "0                2022.0        Good            809.98   \n",
      "1                   4.0        Good            809.98   \n",
      "2                   4.0        Good            809.98   \n",
      "3                   4.0        Good            809.98   \n",
      "4                   5.0        Good            605.03   \n",
      "\n",
      "   Credit_Utilization_Ratio      Credit_History_Age  Payment_of_Min_Amount  \\\n",
      "0                 35.030402   22 Years and 9 Months                     No   \n",
      "1                 33.053114  22 Years and 10 Months                     No   \n",
      "2                 33.811894                     NaN                     No   \n",
      "3                 32.430559   23 Years and 0 Months                     No   \n",
      "4                 25.926822   27 Years and 3 Months                     No   \n",
      "\n",
      "   Total_EMI_per_month Amount_invested_monthly  \\\n",
      "0            49.574949      236.64268203272135   \n",
      "1            49.574949      21.465380264657146   \n",
      "2            49.574949      148.23393788500925   \n",
      "3            49.574949       39.08251089460281   \n",
      "4            18.816215      39.684018417945296   \n",
      "\n",
      "                  Payment_Behaviour     Monthly_Balance  \n",
      "0    Low_spent_Small_value_payments  186.26670208571772  \n",
      "1  High_spent_Medium_value_payments  361.44400385378196  \n",
      "2   Low_spent_Medium_value_payments  264.67544623342997  \n",
      "3  High_spent_Medium_value_payments  343.82687322383634  \n",
      "4   High_spent_Large_value_payments   485.2984336755923  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "‚úÖ Arquivos salvos: train_clean_v1.csv & test_clean_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: PADR√ÉO CURADORIA RAW ‚ûú CLEAN V1 (TRAIN & TEST)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ‚öôÔ∏è Caminhos\n",
    "TRAIN_RAW_PATH = '../data/raw/train.csv'\n",
    "TEST_RAW_PATH  = '../data/raw/test.csv'\n",
    "\n",
    "# 1Ô∏è‚É£ Carrega\n",
    "df_train = pd.read_csv(TRAIN_RAW_PATH)\n",
    "df_test  = pd.read_csv(TEST_RAW_PATH)\n",
    "\n",
    "print(f\"‚úÖ RAW TRAIN shape: {df_train.shape}\")\n",
    "print(f\"‚úÖ RAW TEST shape: {df_test.shape}\")\n",
    "\n",
    "# 2Ô∏è‚É£ Fun√ß√£o padr√£o\n",
    "def clean_pipeline(df):\n",
    "    # Remove IDs\n",
    "    drop_cols = ['ID', 'Customer_ID', 'Name', 'SSN']\n",
    "    df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True, errors='ignore')\n",
    "\n",
    "    # Substitui placeholders\n",
    "    placeholders = ['Unknown', '_______', '!@9#%8', '#F%$D@*&8']\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].replace(placeholders, 'Other')\n",
    "\n",
    "    # Coer√ß√£o num√©rica e corre√ß√£o de outliers\n",
    "    numeric_cols = ['Annual_Income', 'Monthly_Inhand_Salary', 'Changed_Credit_Limit', \n",
    "                    'Outstanding_Debt', 'Age', 'Num_Bank_Accounts', \n",
    "                    'Num_of_Loan', 'Num_of_Delayed_Payment']\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    if 'Age' in df.columns:\n",
    "        df.loc[df['Age'] < 0, 'Age'] = pd.NA\n",
    "\n",
    "    if 'Num_Bank_Accounts' in df.columns:\n",
    "        df.loc[df['Num_Bank_Accounts'] < 0, 'Num_Bank_Accounts'] = 0\n",
    "\n",
    "    # Imputa√ß√£o por Occupation se existir\n",
    "    for col in ['Annual_Income', 'Monthly_Inhand_Salary', 'Changed_Credit_Limit',\n",
    "                'Outstanding_Debt', 'Num_of_Loan', 'Num_of_Delayed_Payment']:\n",
    "        if col in df.columns:\n",
    "            if 'Occupation' in df.columns:\n",
    "                df[col] = df.groupby('Occupation')[col].transform(\n",
    "                    lambda x: x.fillna(x.median())\n",
    "                )\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    if 'Age' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    if 'Num_Bank_Accounts' in df.columns:\n",
    "        df['Num_Bank_Accounts'] = df['Num_Bank_Accounts'].fillna(df['Num_Bank_Accounts'].median())\n",
    "\n",
    "    # Imputa Occupation com moda\n",
    "    if 'Occupation' in df.columns:\n",
    "        df['Occupation'] = df['Occupation'].fillna(df['Occupation'].mode()[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 3Ô∏è‚É£ Aplica\n",
    "df_train_clean = clean_pipeline(df_train)\n",
    "df_test_clean  = clean_pipeline(df_test)\n",
    "\n",
    "print(f\"‚úÖ TRAIN CLEAN V1: {df_train_clean.shape}\")\n",
    "print(f\"‚úÖ TEST CLEAN V1: {df_test_clean.shape}\")\n",
    "\n",
    "print(\"\\nüîç Preview TRAIN CLEAN V1:\")\n",
    "print(df_train_clean.head(5))\n",
    "\n",
    "print(\"\\nüîç Preview TEST CLEAN V1:\")\n",
    "print(df_test_clean.head(5))\n",
    "\n",
    "# 4Ô∏è‚É£ Salva\n",
    "df_train_clean.to_csv('../data/processed/train_clean_v1.csv', index=False)\n",
    "df_test_clean.to_csv('../data/processed/test_clean_v1.csv', index=False)\n",
    "print(\"\\n‚úÖ Arquivos salvos: train_clean_v1.csv & test_clean_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e2bc6",
   "metadata": {},
   "source": [
    "# ‚úÖ STATUS FINAL ‚Äî TRAIN & TEST CLEAN V1\n",
    "\n",
    "- Todos os passos de curadoria foram reaplicados a partir dos datasets `RAW`.\n",
    "- Remo√ß√£o de identificadores, coer√ß√£o de tipos, placeholders padronizados.\n",
    "- Imputa√ß√£o por `Occupation` mantida, sem codifica√ß√£o antecipada.\n",
    "- `Credit_Score` presente apenas no `TRAIN` (24 colunas); ausente no `TEST` (23 colunas) ‚Äî coerente com ML supervisionado.\n",
    "- Ambos versionados como `*_v1.csv`, prontos para rastreio via DVC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215dcfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l‚†ã Checking graph\n",
      "\u001b[?25l‚†ã Checking graph\n",
      "\u001b[?25h\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ dvc add conclu√≠do.\n",
      "2 files pushed\n",
      "\n",
      "‚úÖ dvc push conclu√≠do. Ambos os arquivos est√£o versionados no remote.\n"
     ]
    }
   ],
   "source": [
    "# üîß ETAPA: VERSIONAMENTO VIA DVC NO JUPYTER ‚Äî CLEAN V1\n",
    "\n",
    "\"\"\"\n",
    "1Ô∏è‚É£ Adiciona os arquivos ao DVC tracking.\n",
    "2Ô∏è‚É£ Executa o push para o remote (ex: MinIO).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Caminhos coerentes\n",
    "TRAIN_CLEAN_V1 = '../data/processed/train_clean_v1.csv'\n",
    "TEST_CLEAN_V1 = '../data/processed/test_clean_v1.csv'\n",
    "\n",
    "# 1Ô∏è‚É£ dvc add\n",
    "os.system(f'dvc add {TRAIN_CLEAN_V1}')\n",
    "os.system(f'dvc add {TEST_CLEAN_V1}')\n",
    "\n",
    "print(\"\\n‚úÖ dvc add conclu√≠do.\")\n",
    "\n",
    "# 2Ô∏è‚É£ dvc push\n",
    "os.system('dvc push')\n",
    "\n",
    "print(\"\\n‚úÖ dvc push conclu√≠do. Ambos os arquivos est√£o versionados no remote.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404796f7",
   "metadata": {},
   "source": [
    "## ETAPA CONCLU√çDA ‚Äî CURADORIA RAW ‚ûú CLEAN V1\n",
    "\n",
    "- Finalizamos a nova camada `CLEAN V1` usando pipeline padronizado, aplicando coer√ß√£o de tipos, substitui√ß√£o de placeholders e imputa√ß√£o por grupo `Occupation`.\n",
    "- O kernel anterior estourava por cardinalidade descontrolada em colunas como `Type_of_Loan`, `Payment_Behaviour`, etc.\n",
    "- A partir deste ponto, a an√°lise de cardinalidade ser√° refeita **sobre `TRAIN_CLEAN_V1` e `TEST_CLEAN_V1`**, e n√£o sobre a vers√£o anterior.\n",
    "- O Feature Engineering segue no notebook `feature_engineering_curadoria.ipynb` com blocos autocontidos e sem √≠cones, mantendo rastreabilidade PROTOCOLO V5.4.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
